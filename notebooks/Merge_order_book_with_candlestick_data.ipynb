{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-EViPnrPitGR",
    "outputId": "d0614f8f-5450-46d4-d00f-f2d9e2dcf1e8",
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install pandas pandas-ta plotly ZigZag scipy TA-Lib tensorflow scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "h2Dm9p3kpLW0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 09:00:51.101120: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-24 09:00:51.101190: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "from sklearn.preprocessing import scale\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cj-Ayxtk9wq4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AlGqCKMLei7T",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NAME = 'Merge_order_book_with_candlestick_data'\n",
    "TIME_INTERVAL = 60\n",
    "TAKE_STEPS_TO_WATCH = 256\n",
    "INPUT_WIDTH = 512\n",
    "LSTM_INPUT_WIDTH = 512\n",
    "TAKE_PROFIT_PERCENT = 2\n",
    "STOP_LOSS_PERCENT = 1\n",
    "CURRENCY_PAIR = 'btc_usdt'\n",
    "DROPOUT = 0.01        # 0.1\n",
    "L2_REGULARIZERS = 0.002 # 0.02\n",
    "LOOKAHEAD = False\n",
    "INDICATORS = False\n",
    "EXCHANGE = 'binance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-PrH0opapXA7",
    "outputId": "a96c3e43-2104-42c4-b2d1-2c2274ba7dea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RATES_PATH = f\"{os.getcwd()}/../csv\"\n",
    "ORDERBOOK_PATH = f\"{os.getcwd()}/../csv/order_book\"\n",
    "EXAMPLE_PATH = f\"{os.getcwd()}/checkpoints/\"\n",
    "\n",
    "indicators = ''\n",
    "\n",
    "if INDICATORS is True:\n",
    "    indicators = 'indicators'\n",
    "\n",
    "CHECKPOINT_PATH = f\"{EXAMPLE_PATH}/{NAME} {CURRENCY_PAIR.upper()} {TIME_INTERVAL} steps {TAKE_STEPS_TO_WATCH} iw {INPUT_WIDTH} lstm {LSTM_INPUT_WIDTH} tp {TAKE_PROFIT_PERCENT} sl {STOP_LOSS_PERCENT} {indicators} {EXCHANGE}/\"\n",
    "\n",
    "if not os.path.exists(EXAMPLE_PATH):\n",
    "  os.mkdir(EXAMPLE_PATH)\n",
    "\n",
    "if not os.path.exists(CHECKPOINT_PATH):\n",
    "  os.mkdir(CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SClSJNEipayw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Функция индикаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#@title\n",
    "def append_all_indicators(df):\n",
    "\n",
    "  df = append_candles_indicators(df)\n",
    "  df = append_overlap_indicators(df)\n",
    "  df = append_momentum_indicators(df)\n",
    "  df = append_statistics_indicators(df)\n",
    "  df = append_trend_indicators(df)\n",
    "  df = append_aberration_indicators(df)\n",
    "  df = append_volume_indicators(df)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_candles_indicators(df):\n",
    "\n",
    "  names = [\n",
    "           \"2crows\",\n",
    "          \"3blackcrows\",\n",
    "          \"3inside\",\n",
    "          \"3linestrike\",\n",
    "          \"3outside\",\n",
    "          \"3starsinsouth\",\n",
    "          \"3whitesoldiers\",\n",
    "          \"abandonedbaby\",\n",
    "          \"advanceblock\",\n",
    "          \"belthold\",\n",
    "          \"breakaway\",\n",
    "          \"closingmarubozu\",\n",
    "          \"concealbabyswall\",\n",
    "          \"counterattack\",\n",
    "          \"darkcloudcover\",\n",
    "          \"doji\",\n",
    "          \"dojistar\",\n",
    "          \"dragonflydoji\",\n",
    "          \"engulfing\",\n",
    "          \"eveningdojistar\",\n",
    "          \"eveningstar\",\n",
    "          \"gapsidesidewhite\",\n",
    "          \"gravestonedoji\",\n",
    "          \"hammer\",\n",
    "          \"hangingman\",\n",
    "          \"harami\",\n",
    "          \"haramicross\",\n",
    "          \"highwave\",\n",
    "          \"hikkake\",\n",
    "          \"hikkakemod\",\n",
    "          \"homingpigeon\",\n",
    "          \"identical3crows\",\n",
    "          \"inneck\",\n",
    "          \"inside\",\n",
    "          \"invertedhammer\",\n",
    "          \"kicking\",\n",
    "          \"kickingbylength\",\n",
    "          \"ladderbottom\",\n",
    "          \"longleggeddoji\",\n",
    "          \"longline\",\n",
    "          \"marubozu\",\n",
    "          \"matchinglow\",\n",
    "          \"mathold\",\n",
    "          \"morningdojistar\",\n",
    "          \"morningstar\",\n",
    "          \"onneck\",\n",
    "          \"piercing\",\n",
    "          \"rickshawman\",\n",
    "          \"risefall3methods\",\n",
    "          \"separatinglines\",\n",
    "          \"shootingstar\",\n",
    "          \"shortline\",\n",
    "          \"spinningtop\",\n",
    "          \"stalledpattern\",\n",
    "          \"sticksandwich\",\n",
    "          \"takuri\",\n",
    "          \"tasukigap\",\n",
    "          \"thrusting\",\n",
    "          \"tristar\",\n",
    "          \"unique3river\",\n",
    "          \"upsidegap2crows\",\n",
    "          \"xsidegap3methods\"\n",
    "  ]\n",
    "\n",
    "  df.ta.cdl_pattern(name=names, append=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_momentum_indicators(df):\n",
    "\n",
    "  df.ta.apo(append=True)\n",
    "  df.ta.bias(append=True)\n",
    "  df.ta.bop(append=True)\n",
    "  df.ta.brar(append=True)\n",
    "  df.ta.cci(append=True)\n",
    "  df.ta.cfo(append=True)\n",
    "  df.ta.cg(append=True)\n",
    "  df.ta.cmo(append=True)\n",
    "  df.ta.coppock(append=True)\n",
    "  df.ta.cti(append=True)\n",
    "  df.ta.dm(append=True)\n",
    "  df.ta.er(append=True)\n",
    "  df.ta.eri(append=True)\n",
    "  df.ta.fisher(append=True)\n",
    "  df.ta.inertia(append=True)\n",
    "  df.ta.kdj(append=True)\n",
    "  df.ta.kst(append=True)\n",
    "  df.ta.macd(append=True, )\n",
    "  df.ta.mom(append=True)\n",
    "  df.ta.pgo(append=True)\n",
    "  df.ta.ppo(append=True)\n",
    "  df.ta.psl(append=True)\n",
    "  df.ta.pvo(append=True)\n",
    "  df.ta.qqe(append=True)\n",
    "  df.ta.roc(append=True)\n",
    "  df.ta.rsi(append=True)\n",
    "  df.ta.rsx(append=True)\n",
    "  df.ta.rvgi(append=True)\n",
    "  # df.ta.stc(append=True) вываливается ошибка\n",
    "  df.ta.slope(append=True)\n",
    "  df.ta.smi(append=True)\n",
    "  df.ta.squeeze(append=True)\n",
    "  df.ta.squeeze_pro(append=True)\n",
    "  df.ta.stoch(append=True)\n",
    "  df.ta.stochrsi(append=True)\n",
    "  #df.ta.td_seq(append=True)   # медленный\n",
    "  df['TD_SEQ_UP'] = 0\n",
    "  df['TD_SEQ_DN'] = 0\n",
    "  df.ta.trix(append=True)\n",
    "  df.ta.tsi(append=True)\n",
    "  df.ta.uo(append=True)\n",
    "  df.ta.willr(append=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_overlap_indicators(df):\n",
    "\n",
    "  df.ta.alma(append=True)\n",
    "  df.ta.dema(append=True)\n",
    "  df.ta.ema(append=True)\n",
    "  df.ta.fwma(append=True)\n",
    "  df.ta.hilo(append=True)\n",
    "  df.ta.hl2(append=True)\n",
    "  df.ta.hlc3(append=True)\n",
    "  df.ta.hma(append=True)\n",
    "  df.ta.hwma(append=True)\n",
    "  #df.ta.ichimoku(append=True, lookahead=LOOKAHEAD) # data leak\n",
    "  #df.ta.jma(append=True)\n",
    "  df.ta.kama(append=True)\n",
    "  df.ta.linreg(append=True)\n",
    "  df.ta.mcgd(append=True)\n",
    "  df.ta.midpoint(append=True)\n",
    "  df.ta.midprice(append=True)\n",
    "  df.ta.ohlc4(append=True)\n",
    "  df.ta.pwma(append=True)\n",
    "  df.ta.rma(append=True)\n",
    "  df.ta.sinwma(append=True)\n",
    "  df.ta.sma(append=True)\n",
    "  df.ta.ssf(append=True)\n",
    "  df.ta.supertrend(append=True)\n",
    "  df.ta.swma(append=True)\n",
    "  df.ta.t3(append=True)\n",
    "  df.ta.tema(append=True)\n",
    "  df.ta.trima(append=True)\n",
    "  df.ta.vidya(append=True)\n",
    "  #df.ta.vwap(append=True) ошибка\n",
    "  df.ta.vwma(append=True)\n",
    "  df.ta.wcp(append=True)\n",
    "  df.ta.wma(append=True)\n",
    "  df.ta.zlma(append=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_statistics_indicators(df):\n",
    "  df.ta.entropy(append=True)\n",
    "  df.ta.kurtosis(append=True)\n",
    "  df.ta.mad(append=True)\n",
    "  df.ta.median(append=True)\n",
    "  df.ta.quantile(append=True)\n",
    "  df.ta.skew(append=True)\n",
    "  df.ta.stdev(append=True)\n",
    "\n",
    "  if LOOKAHEAD:\n",
    "    df.ta.tos_stdevall(append=True) #возможная утечка данных в будущее\n",
    "  else:\n",
    "    df['TOS_STDEVALL_LR'] = 0\n",
    "    df['TOS_STDEVALL_L_1'] = 0\n",
    "    df['TOS_STDEVALL_U_1'] = 0\n",
    "    df['TOS_STDEVALL_L_2'] = 0\n",
    "    df['TOS_STDEVALL_U_2'] = 0\n",
    "    df['TOS_STDEVALL_L_3'] = 0\n",
    "    df['TOS_STDEVALL_U_3'] = 0\n",
    "\n",
    "  df.ta.variance(append=True)\n",
    "  df.ta.zscore(append=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_trend_indicators(df):\n",
    "  df.ta.adx(append=True)\n",
    "  df.ta.amat(append=True)\n",
    "  df.ta.aroon(append=True)\n",
    "  df.ta.chop(append=True)\n",
    "  df.ta.cksp(append=True)\n",
    "  #df.ta.decay(append=True) ошибка\n",
    "  df.ta.decreasing(append=True)\n",
    "  df.ta.dpo(append=True, lookahead=LOOKAHEAD) # data leak\n",
    "  df.ta.increasing(append=True)\n",
    "  df.ta.long_run(append=True)\n",
    "  df.ta.psar(append=True)\n",
    "  df.ta.qstick(append=True)\n",
    "  df.ta.short_run(append=True)\n",
    "  df.ta.tsignals(append=True)\n",
    "  df.ta.ttm_trend(append=True)\n",
    "  df.ta.vhf(append=True)\n",
    "  df.ta.vortex(append=True)\n",
    "  df.ta.xsignals(append=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_utility_indicators(df):\n",
    "  # не работают\n",
    "  df.ta.above(append=True)\n",
    "  df.ta.above_value(append=True)\n",
    "  df.ta.below(append=True)\n",
    "  df.ta.below_value(append=True)\n",
    "  df.ta.cross(append=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_aberration_indicators(df):\n",
    "  df.ta.aberration(append=True)\n",
    "  df.ta.accbands(append=True)\n",
    "  df.ta.atr(append=True)\n",
    "  df.ta.bbands(append=True)\n",
    "  df.ta.donchian(append=True)\n",
    "  #df.ta.hwc(append=True) ошибка\n",
    "  df.ta.kc(append=True)\n",
    "  df.ta.massi(append=True)\n",
    "  df.ta.natr(append=True)\n",
    "  df.ta.pdist(append=True)\n",
    "  df.ta.rvi(append=True)\n",
    "  df.ta.thermo(append=True)\n",
    "  df.ta.true_range(append=True)\n",
    "  df.ta.ui(append=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_volume_indicators(df):\n",
    "  df.ta.ad(append=True)\n",
    "  df.ta.adosc(append=True)\n",
    "  df.ta.aobv(append=True)\n",
    "  df.ta.cmf(append=True)\n",
    "  df.ta.efi(append=True)\n",
    "  df.ta.eom(append=True)\n",
    "  df.ta.kvo(append=True)\n",
    "  df.ta.mfi(append=True)\n",
    "  df.ta.nvi(append=True)\n",
    "  df.ta.obv(append=True)\n",
    "  df.ta.pvi(append=True)\n",
    "  df.ta.pvol(append=True)\n",
    "  df.ta.pvr(append=True)\n",
    "  df.ta.pvt(append=True)\n",
    "  df.ta.vp(append=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_cycles(df):\n",
    "  #df.ta.ebsw(append=True) появляется ошибка\n",
    "\n",
    "  return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WdDeR-VtrjOf",
    "outputId": "3036db70-6edc-4a29-e415-42d7c26884d8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_candlesticks():\n",
    "    file_name = f'{CURRENCY_PAIR}_{TIME_INTERVAL}.csv.zip'\n",
    "\n",
    "    file_path = f'file://{RATES_PATH}/{file_name}'\n",
    "\n",
    "    df = pd.read_csv(file_path, decimal='.', keep_default_na=False, encoding = \"UTF-8\", compression='zip')\n",
    "\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "    df['timestamp'] = df['datetime'].values.astype('int') / 10 ** 9\n",
    "\n",
    "    df = df.drop_duplicates(subset=['timestamp'])\n",
    "\n",
    "    df = df.set_index('timestamp')\n",
    "\n",
    "    return (df.replace((np.inf, -np.inf), np.nan).dropna())\n",
    "\n",
    "candlesticks_df = load_candlesticks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "if INDICATORS:\n",
    "    candlesticks_df = append_all_indicators(candlesticks_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                        datetime      open     close       low      high  \\\ntimestamp                                                                  \n1.568651e+09 2019-09-16 16:25:00  10150.00  10150.00  10150.00  10151.84   \n1.568651e+09 2019-09-16 16:26:00  10141.00  10141.00  10141.00  10141.00   \n1.568651e+09 2019-09-16 16:27:00  10141.01  10141.03  10141.01  10141.03   \n1.568651e+09 2019-09-16 16:28:00  10141.03  10141.00  10141.00  10141.03   \n1.568651e+09 2019-09-16 16:29:00  10141.01  10141.01  10141.01  10141.01   \n1.568651e+09 2019-09-16 16:30:00  10150.90  10142.00  10142.00  10150.90   \n1.568651e+09 2019-09-16 16:31:00  10142.00  10141.01  10141.00  10142.00   \n1.568652e+09 2019-09-16 16:32:00  10141.01  10150.76  10141.00  10150.76   \n1.568652e+09 2019-09-16 16:33:00  10150.76  10150.76  10150.76  10150.76   \n1.568652e+09 2019-09-16 16:34:00  10142.02  10141.00  10141.00  10142.02   \n\n                volume  \ntimestamp               \n1.568651e+09  0.254659  \n1.568651e+09  0.339400  \n1.568651e+09  0.007500  \n1.568651e+09  0.142097  \n1.568651e+09  0.005900  \n1.568651e+09  0.332100  \n1.568651e+09  0.189090  \n1.568652e+09  0.073300  \n1.568652e+09  0.000000  \n1.568652e+09  0.668600  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>open</th>\n      <th>close</th>\n      <th>low</th>\n      <th>high</th>\n      <th>volume</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1.568651e+09</th>\n      <td>2019-09-16 16:25:00</td>\n      <td>10150.00</td>\n      <td>10150.00</td>\n      <td>10150.00</td>\n      <td>10151.84</td>\n      <td>0.254659</td>\n    </tr>\n    <tr>\n      <th>1.568651e+09</th>\n      <td>2019-09-16 16:26:00</td>\n      <td>10141.00</td>\n      <td>10141.00</td>\n      <td>10141.00</td>\n      <td>10141.00</td>\n      <td>0.339400</td>\n    </tr>\n    <tr>\n      <th>1.568651e+09</th>\n      <td>2019-09-16 16:27:00</td>\n      <td>10141.01</td>\n      <td>10141.03</td>\n      <td>10141.01</td>\n      <td>10141.03</td>\n      <td>0.007500</td>\n    </tr>\n    <tr>\n      <th>1.568651e+09</th>\n      <td>2019-09-16 16:28:00</td>\n      <td>10141.03</td>\n      <td>10141.00</td>\n      <td>10141.00</td>\n      <td>10141.03</td>\n      <td>0.142097</td>\n    </tr>\n    <tr>\n      <th>1.568651e+09</th>\n      <td>2019-09-16 16:29:00</td>\n      <td>10141.01</td>\n      <td>10141.01</td>\n      <td>10141.01</td>\n      <td>10141.01</td>\n      <td>0.005900</td>\n    </tr>\n    <tr>\n      <th>1.568651e+09</th>\n      <td>2019-09-16 16:30:00</td>\n      <td>10150.90</td>\n      <td>10142.00</td>\n      <td>10142.00</td>\n      <td>10150.90</td>\n      <td>0.332100</td>\n    </tr>\n    <tr>\n      <th>1.568651e+09</th>\n      <td>2019-09-16 16:31:00</td>\n      <td>10142.00</td>\n      <td>10141.01</td>\n      <td>10141.00</td>\n      <td>10142.00</td>\n      <td>0.189090</td>\n    </tr>\n    <tr>\n      <th>1.568652e+09</th>\n      <td>2019-09-16 16:32:00</td>\n      <td>10141.01</td>\n      <td>10150.76</td>\n      <td>10141.00</td>\n      <td>10150.76</td>\n      <td>0.073300</td>\n    </tr>\n    <tr>\n      <th>1.568652e+09</th>\n      <td>2019-09-16 16:33:00</td>\n      <td>10150.76</td>\n      <td>10150.76</td>\n      <td>10150.76</td>\n      <td>10150.76</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1.568652e+09</th>\n      <td>2019-09-16 16:34:00</td>\n      <td>10142.02</td>\n      <td>10141.00</td>\n      <td>10141.00</td>\n      <td>10142.02</td>\n      <td>0.668600</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candlesticks_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def load_orderbook():\n",
    "    file_name = f'order_book_{EXCHANGE}_{CURRENCY_PAIR}_{TIME_INTERVAL}.csv.zip'\n",
    "\n",
    "    file_path = f'file://{ORDERBOOK_PATH}/{file_name}'\n",
    "\n",
    "    df = pd.read_csv(file_path, decimal='.', keep_default_na=False, encoding = \"UTF-8\", compression='zip')\n",
    "\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "    df['datetime'] = df['datetime'].dt.floor('T')\n",
    "\n",
    "    df['timestamp'] = df['datetime'].values.astype('int') / 10 ** 9\n",
    "\n",
    "    df = df.drop_duplicates(subset=['timestamp'])\n",
    "\n",
    "    df = df.set_index('timestamp')\n",
    "\n",
    "    return (df.replace((np.inf, -np.inf), np.nan).dropna())\n",
    "\n",
    "orderbook_df = load_orderbook()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "                        datetime       asks       bids\ntimestamp                                             \n1.652954e+09 2022-05-19 09:49:00  243.39134  367.23632\n1.652954e+09 2022-05-19 09:50:00  250.75648  367.45799\n1.652954e+09 2022-05-19 09:51:00  318.21946  384.56824\n1.652954e+09 2022-05-19 09:52:00  333.41531  453.30601\n1.652954e+09 2022-05-19 09:53:00  340.42332  454.15463\n1.652954e+09 2022-05-19 09:54:00  276.89298  454.26024\n1.652954e+09 2022-05-19 09:55:00  333.05469  429.23010\n1.652954e+09 2022-05-19 09:56:00  335.29685  459.45611\n1.652954e+09 2022-05-19 09:57:00  237.64129  330.27589\n1.652954e+09 2022-05-19 09:58:00  293.66285  452.40613",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>asks</th>\n      <th>bids</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1.652954e+09</th>\n      <td>2022-05-19 09:49:00</td>\n      <td>243.39134</td>\n      <td>367.23632</td>\n    </tr>\n    <tr>\n      <th>1.652954e+09</th>\n      <td>2022-05-19 09:50:00</td>\n      <td>250.75648</td>\n      <td>367.45799</td>\n    </tr>\n    <tr>\n      <th>1.652954e+09</th>\n      <td>2022-05-19 09:51:00</td>\n      <td>318.21946</td>\n      <td>384.56824</td>\n    </tr>\n    <tr>\n      <th>1.652954e+09</th>\n      <td>2022-05-19 09:52:00</td>\n      <td>333.41531</td>\n      <td>453.30601</td>\n    </tr>\n    <tr>\n      <th>1.652954e+09</th>\n      <td>2022-05-19 09:53:00</td>\n      <td>340.42332</td>\n      <td>454.15463</td>\n    </tr>\n    <tr>\n      <th>1.652954e+09</th>\n      <td>2022-05-19 09:54:00</td>\n      <td>276.89298</td>\n      <td>454.26024</td>\n    </tr>\n    <tr>\n      <th>1.652954e+09</th>\n      <td>2022-05-19 09:55:00</td>\n      <td>333.05469</td>\n      <td>429.23010</td>\n    </tr>\n    <tr>\n      <th>1.652954e+09</th>\n      <td>2022-05-19 09:56:00</td>\n      <td>335.29685</td>\n      <td>459.45611</td>\n    </tr>\n    <tr>\n      <th>1.652954e+09</th>\n      <td>2022-05-19 09:57:00</td>\n      <td>237.64129</td>\n      <td>330.27589</td>\n    </tr>\n    <tr>\n      <th>1.652954e+09</th>\n      <td>2022-05-19 09:58:00</td>\n      <td>293.66285</td>\n      <td>452.40613</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orderbook_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "candlesticks_df['asks'] = orderbook_df['asks']\n",
    "candlesticks_df['bids'] = orderbook_df['bids']\n",
    "\n",
    "candlesticks_df = candlesticks_df[candlesticks_df['asks'].notna()]\n",
    "candlesticks_df = candlesticks_df[candlesticks_df['bids'].notna()]\n",
    "df = candlesticks_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "QHqsoesS3rgP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def processing(df, row, take_steps_to_watch):\n",
    "\n",
    "  index = row.name\n",
    "\n",
    "  loc = df.index.get_loc(index) + 1\n",
    "\n",
    "  sample = df.iloc[loc:loc + take_steps_to_watch]\n",
    "\n",
    "  position = 0\n",
    "\n",
    "  for index, sample_row in sample.iterrows():\n",
    "    if sample_row['high'] >= row['long_take_profit_price']:\n",
    "      return 1\n",
    "    if sample_row['low'] <= row['long_stop_loss_price']:\n",
    "      return 0\n",
    "      \n",
    "  return position\n",
    "\n",
    "def append_position(original_df):\n",
    "\n",
    "  df = original_df.copy()\n",
    "\n",
    "  df['long_take_profit_price'] = (100 + TAKE_PROFIT_PERCENT) * df['close'] / 100\n",
    "  df['long_stop_loss_price'] = (100 - STOP_LOSS_PERCENT) * df['close'] / 100\n",
    "\n",
    "  for index, row in df.iterrows():\n",
    "    df.at[index, 'position'] = processing(df, row, TAKE_STEPS_TO_WATCH)\n",
    "\n",
    "  original_df['position'] = df['position']\n",
    "\n",
    "  return original_df\n",
    "\n",
    "df = append_position(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "S5QWK_fG0RG-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def append_position(original_df):\n",
    "\n",
    "  df = original_df.copy()\n",
    "\n",
    "  df[f'future_high_{TAKE_STEPS_TO_WATCH}'] = df['high'].rolling(TAKE_STEPS_TO_WATCH).max().shift(-TAKE_STEPS_TO_WATCH)\n",
    "  df[f'future_low_{TAKE_STEPS_TO_WATCH}'] = df['low'].rolling(TAKE_STEPS_TO_WATCH).min().shift(-TAKE_STEPS_TO_WATCH)\n",
    "\n",
    "  df[f'future_high_{TAKE_STEPS_TO_WATCH}_percentage'] = (df[f'future_high_{TAKE_STEPS_TO_WATCH}'] * 100 / df['close']) - 100\n",
    "  df[f'future_low_{TAKE_STEPS_TO_WATCH}_percentage'] = 100 - (df[f'future_low_{TAKE_STEPS_TO_WATCH}'] * 100 / df['close'])\n",
    "\n",
    "  df['long_position'] = 0\n",
    "\n",
    "  df.loc[(df[f'future_high_{TAKE_STEPS_TO_WATCH}_percentage'] > TAKE_PROFIT_PERCENT) & (df[f'future_low_{TAKE_STEPS_TO_WATCH}_percentage'] < STOP_LOSS_PERCENT), 'long_position'] = 1\n",
    "\n",
    "  df['short_position'] = 0\n",
    "\n",
    "  df.loc[(df[f'future_high_{TAKE_STEPS_TO_WATCH}_percentage'] < STOP_LOSS_PERCENT) & (df[f'future_low_{TAKE_STEPS_TO_WATCH}_percentage'] > TAKE_PROFIT_PERCENT), 'short_position'] = 1\n",
    "\n",
    "  df['position'] = 0\n",
    "\n",
    "  df.loc[df['long_position'] > 0, 'position'] = 1\n",
    "  df.loc[df['short_position'] > 0, 'position'] = -1\n",
    "\n",
    "  original_df['position'] = df['position']\n",
    "\n",
    "  return original_df\n",
    "\n",
    "#df = append_position(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdoSQg9EIT85",
    "outputId": "041f5261-0d47-4a68-e736-2ba7888c17a2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long trend count: 2508\n",
      "Neutral trend count: 26575\n",
      "Short trend count: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Long trend count:\", len(df[df['position'] > 0]))\n",
    "print(\"Neutral trend count:\", len(df[df['position'] == 0]))\n",
    "print(\"Short trend count:\", len(df[df['position'] < 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XizdWj5Ccp-o",
    "outputId": "d8e1fff6-7cbc-44ed-ae97-d52fbb1cfcf0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['asks', 'bids'], dtype=object)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = df.columns\n",
    "\n",
    "features_names_with_position = index.delete([\n",
    "                                             index.get_loc('datetime'),\n",
    "                                             index.get_loc('volume'), \n",
    "                                             index.get_loc('close'),\n",
    "                                             index.get_loc('open'), \n",
    "                                             index.get_loc('high'), \n",
    "                                             index.get_loc('low'),\n",
    "                                             ])\n",
    "\n",
    "FEATURES_NAMES = features_names_with_position.delete([features_names_with_position.get_loc('position')]).values\n",
    "\n",
    "FEATURES_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Sno5eQ3QgcKd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = df.loc[:,features_names_with_position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n = len(data)\n",
    "max_val_df_length = 2000\n",
    "max_eval_df_length = 2000\n",
    "val_length = int(n*0.9) - int(n*0.8)\n",
    "eval_length = int(n*1) - int(n*0.9)\n",
    "\n",
    "if val_length > max_val_df_length:\n",
    "    val_length = max_val_df_length\n",
    "    \n",
    "if eval_length > max_eval_df_length:\n",
    "    eval_length = max_eval_df_length\n",
    "\n",
    "val_start_index = n - eval_length - val_length\n",
    "test_start_index = n - eval_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29083 25083 27083\n"
     ]
    }
   ],
   "source": [
    "print(len(data), val_start_index, test_start_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SNcqnMrogkv7",
    "outputId": "a7ed430c-7d35-4d2c-ca49-47026dcace3f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df = data.iloc[0:val_start_index]\n",
    "val_df = data.iloc[val_start_index:test_start_index]\n",
    "test_df = data.iloc[test_start_index:]\n",
    "\n",
    "test_full_df = df.iloc[test_start_index:]\n",
    "\n",
    "num_features = data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29083 25083 2000 2000\n"
     ]
    }
   ],
   "source": [
    "print(len(data), len(train_df), len(val_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Oiad03Ja3LPH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalization(dataframe, train_mean, train_std):\n",
    "  position = dataframe.pop('position')\n",
    "  dataframe = (dataframe - train_mean) / train_std\n",
    "  dataframe['position'] = position\n",
    "  return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzjrB6DCgtsK",
    "outputId": "2aecd1ee-f74d-404f-a7b4-35832f8af872",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_df = normalization(train_df, train_mean, train_std)\n",
    "val_df = normalization(val_df, train_mean, train_std)\n",
    "test_df = normalization(test_df, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7801Z5WwgwDi",
    "outputId": "2c6ebe1d-bde6-401c-ed06-d3cb4d4ab527",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asks        354.564047\n",
      "bids        500.942878\n",
      "position      0.072479\n",
      "dtype: float64 asks        130.459269\n",
      "bids        498.387881\n",
      "position      0.259285\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u492P34ygy-S",
    "outputId": "86be81f3-9340-465a-d879-6eacb9285357",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25083 2000 2000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df), len(val_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "vB4ypH2Hjbht",
    "outputId": "a0522a28-aa8f-48f1-a0f2-b32dd7b9f7e7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [asks, bids, position]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>asks</th>\n      <th>bids</th>\n      <th>position</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.fillna(0)\n",
    "val_df = val_df.fillna(0)\n",
    "test_df = test_df.fillna(0)\n",
    "\n",
    "train_df[train_df.isnull().any(axis=1)]\n",
    "train_df[train_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "f9ARLeUAg2ua",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert train_df.isnull().values.any() == False, 'Тренировочный датафрейм не должен содержать nan значений'\n",
    "assert val_df.isnull().values.any() == False, 'Датафрейм валидации не должен содержать nan значений'\n",
    "assert test_df.isnull().values.any() == False, 'Тестовый датафрейм не должен содержать nan значений'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "IDwhAGpWceQJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,\n",
    "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "               label_columns=None, input_columns=None):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    # Work out the label column indices.\n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "\n",
    "    self.input_columns = input_columns\n",
    "\n",
    "    self.input_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(input_columns)}   \n",
    "\n",
    "    self.label_columns = label_columns\n",
    "\n",
    "    self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}                       \n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "  def __repr__(self):\n",
    "    return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Column indices: {self.column_indices}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}',\n",
    "        f'Label start: {self.label_start}',\n",
    "        f'Input width: {self.input_width}',\n",
    "        f'Label width: {self.label_width}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "JaaeyIqnciCo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_dataset(self, data, shuffle=True, batch_size=32,):\n",
    "  data = np.array(data, dtype=np.float32)\n",
    "\n",
    "  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size)\n",
    "\n",
    "  ds = ds.map(self.split_window)\n",
    "\n",
    "  return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "38kyb3tPckMp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@property\n",
    "def train(self):\n",
    "  return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "  return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "  return self.make_dataset(self.test_df)\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "  result = getattr(self, '_example', None)\n",
    "  if result is None:\n",
    "    # No example batch was found, so get one from the `.train` dataset\n",
    "    result = next(iter(self.train))\n",
    "    # And cache it for next time\n",
    "    self._example = result\n",
    "  return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "la6ecAfPcgq4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_window(self, features):\n",
    "  inputs = features[:, self.input_slice, :]\n",
    "  labels = features[:, self.labels_slice, :]\n",
    "\n",
    "  inputs = tf.stack(\n",
    "        [inputs[:, :, self.column_indices[name]] for name in self.input_columns],\n",
    "        axis=-1)\n",
    "  \n",
    "  labels = tf.stack(\n",
    "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "        axis=-1)\n",
    "\n",
    "  # Slicing doesn't preserve static shape information, so set the shapes\n",
    "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "  inputs.set_shape([None, self.input_width, None])\n",
    "  labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "  return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "iUY869JCcgw3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "  def __init__(self, model, path, max_epochs=30, patience=3):\n",
    "    self.model = model\n",
    "    self.path = path\n",
    "    self.max_epochs = max_epochs\n",
    "    self.patience = patience\n",
    "\n",
    "  def compile(self):\n",
    "    self.model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                  optimizer=tf.optimizers.Adam(learning_rate=0.0005),\n",
    "                  metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "  def load_weights(self):\n",
    "    self.model.load_weights(self.path)\n",
    "\n",
    "  def fit(self, window):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                      patience=self.patience,\n",
    "                                                      mode='min')\n",
    "\n",
    "    # Create a callback that saves the model's weights\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=self.path,\n",
    "                                                    save_weights_only=True,\n",
    "                                                    verbose=1)\n",
    "\n",
    "    history = self.model.fit(window.train, epochs=self.max_epochs,\n",
    "                        validation_data=window.val,\n",
    "                        callbacks=[early_stopping, cp_callback])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "FV4lB3DXcifH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wide_window = WindowGenerator(\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    input_width=INPUT_WIDTH, label_width=1, shift=1,\n",
    "    label_columns=['position'], input_columns=FEATURES_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "zj4BOQBYhRXI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 09:09:52.935487: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-24 09:09:52.935528: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-24 09:09:52.935548: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (NEON-WORKPC): /proc/driver/nvidia/version does not exist\n",
      "2022-06-24 09:09:52.936405: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(LSTM_INPUT_WIDTH, activation='tanh', return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(L2_REGULARIZERS)),\n",
    "    tf.keras.layers.Dropout(DROPOUT),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQIR9s1MpgMp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Тренировка нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "_tI8qaAXmGcS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(lstm_model, CHECKPOINT_PATH, max_epochs=20, patience=3)\n",
    "model.compile()\n",
    "\n",
    "if os.path.exists(f'{CHECKPOINT_PATH}/checkpoint'):\n",
    "  model.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SOYH_oU4AUnr",
    "outputId": "10203c13-92e6-4956-8154-ca12fbeb8d82",
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.0597 - mean_absolute_error: 0.1162\n",
      "Epoch 1: saving model to /mnt/d/Users/Neon/PycharmProjects/tradingBot/notebooks/checkpoints//Merge_order_book_with_candlestick_data BTC_USDT 60 steps 256 iw 512 lstm 512 tp 2 sl 1  binance/\n",
      "768/768 [==============================] - 1500s 2s/step - loss: 0.0597 - mean_absolute_error: 0.1162 - val_loss: 0.0023 - val_mean_absolute_error: 0.0332\n",
      "Epoch 2/20\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.0578 - mean_absolute_error: 0.1152\n",
      "Epoch 2: saving model to /mnt/d/Users/Neon/PycharmProjects/tradingBot/notebooks/checkpoints//Merge_order_book_with_candlestick_data BTC_USDT 60 steps 256 iw 512 lstm 512 tp 2 sl 1  binance/\n",
      "768/768 [==============================] - 1415s 2s/step - loss: 0.0578 - mean_absolute_error: 0.1152 - val_loss: 0.0024 - val_mean_absolute_error: 0.0426\n",
      "Epoch 3/20\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.0576 - mean_absolute_error: 0.1150\n",
      "Epoch 3: saving model to /mnt/d/Users/Neon/PycharmProjects/tradingBot/notebooks/checkpoints//Merge_order_book_with_candlestick_data BTC_USDT 60 steps 256 iw 512 lstm 512 tp 2 sl 1  binance/\n",
      "768/768 [==============================] - 1446s 2s/step - loss: 0.0576 - mean_absolute_error: 0.1150 - val_loss: 0.0022 - val_mean_absolute_error: 0.0377\n",
      "Epoch 4/20\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.0575 - mean_absolute_error: 0.1152\n",
      "Epoch 4: saving model to /mnt/d/Users/Neon/PycharmProjects/tradingBot/notebooks/checkpoints//Merge_order_book_with_candlestick_data BTC_USDT 60 steps 256 iw 512 lstm 512 tp 2 sl 1  binance/\n",
      "768/768 [==============================] - 1473s 2s/step - loss: 0.0575 - mean_absolute_error: 0.1152 - val_loss: 0.0015 - val_mean_absolute_error: 0.0258\n",
      "Epoch 5/20\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.0574 - mean_absolute_error: 0.1141\n",
      "Epoch 5: saving model to /mnt/d/Users/Neon/PycharmProjects/tradingBot/notebooks/checkpoints//Merge_order_book_with_candlestick_data BTC_USDT 60 steps 256 iw 512 lstm 512 tp 2 sl 1  binance/\n",
      "768/768 [==============================] - 1417s 2s/step - loss: 0.0574 - mean_absolute_error: 0.1141 - val_loss: 0.0024 - val_mean_absolute_error: 0.0404\n",
      "Epoch 6/20\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.0575 - mean_absolute_error: 0.1143\n",
      "Epoch 6: saving model to /mnt/d/Users/Neon/PycharmProjects/tradingBot/notebooks/checkpoints//Merge_order_book_with_candlestick_data BTC_USDT 60 steps 256 iw 512 lstm 512 tp 2 sl 1  binance/\n",
      "768/768 [==============================] - 1449s 2s/step - loss: 0.0575 - mean_absolute_error: 0.1143 - val_loss: 0.0027 - val_mean_absolute_error: 0.0463\n",
      "Epoch 7/20\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.0573 - mean_absolute_error: 0.1137\n",
      "Epoch 7: saving model to /mnt/d/Users/Neon/PycharmProjects/tradingBot/notebooks/checkpoints//Merge_order_book_with_candlestick_data BTC_USDT 60 steps 256 iw 512 lstm 512 tp 2 sl 1  binance/\n",
      "768/768 [==============================] - 1455s 2s/step - loss: 0.0573 - mean_absolute_error: 0.1137 - val_loss: 0.0018 - val_mean_absolute_error: 0.0327\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7ffac5d7d2d0>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(wide_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "29HDmO6QH7SH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@property\n",
    "def test_without_shuffle(self):\n",
    "\n",
    "  return self.make_dataset(self.test_df, shuffle=False)\n",
    "\n",
    "WindowGenerator.test_without_shuffle = test_without_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "ZthrB3EB0td6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "iXwTd2Gshwta",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 32s 670ms/step - loss: 0.2362 - mean_absolute_error: 0.2688\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.23620988428592682, 0.26880747079849243]"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(wide_window.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "AvkBGld3INOX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = wide_window.test_without_shuffle.map(lambda x, y: model(x)).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "QNejnl8OvbA_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index = test_full_df.iloc[0].name\n",
    "\n",
    "before = np.full(INPUT_WIDTH, 0.0)\n",
    "after = np.fromiter(dataset.as_numpy_iterator(), np.float32)\n",
    "\n",
    "position_prediction_df = pd.DataFrame(data=np.concatenate((before, after), axis=0), columns=['position'], index=test_full_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "oyl4hhCnvl8d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataframe_with_prediction = pd.concat([position_prediction_df, test_full_df.drop(columns=['position'])], axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "PYGucvT_mS66",
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_656/2657019458.py:179: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def open_order(self, index: int, open_datetime: np.str):\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "from pandas import DataFrame\n",
    "class Strategy:\n",
    "    fee = 0.2\n",
    "    # ограничение на максимальное количество открытых сделок\n",
    "    max_simultaneous_open_trades_limit = 1\n",
    "    # максимальное количество сделок которое было открыто одновременно\n",
    "    max_simultaneous_open_trades_count = 0\n",
    "\n",
    "    def __init__(self, max_simultaneous_open_trades_limit=1, start_balance=1000):\n",
    "        self.orders = pd.DataFrame(None,\n",
    "                                   columns=['type', 'open_price', 'open_datetime', 'close_price', 'close_datetime',\n",
    "                                            'profit', 'quantity', 'profit_as_a_percentage', 'take_profit_percentage',\n",
    "                                            'stop_loss_percentage', 'take_profit_price', 'stop_loss_price'],\n",
    "                                   ).astype({\n",
    "            'type': str, 'open_price': np.float32, 'open_datetime': str, 'close_price': np.float32,\n",
    "            'close_datetime': str,\n",
    "            'profit': np.float32, 'quantity': np.float32,\n",
    "            'profit_as_a_percentage': np.float32, 'take_profit_percentage': np.float32,\n",
    "            'stop_loss_percentage': np.float32, 'take_profit_price': np.float32, 'stop_loss_price': np.float32\n",
    "        })\n",
    "\n",
    "        self.max_simultaneous_open_trades_limit = max_simultaneous_open_trades_limit\n",
    "        self.start_balance = start_balance\n",
    "        self.balance = start_balance\n",
    "\n",
    "    def append_indicators(self, df: DataFrame) -> DataFrame:\n",
    "        return df\n",
    "\n",
    "    def get_orders(self):\n",
    "        return self.orders\n",
    "\n",
    "    def put_order(self, type: str, price: float, quantity: float, datetime: str = None,\n",
    "                  close_price: float = None, close_datetime: str = None,\n",
    "                  take_profit_percentage: float = None,\n",
    "                  stop_loss_percentage: float = None) -> int:\n",
    "\n",
    "        row = {\n",
    "            'type': type,\n",
    "            'open_price': price,\n",
    "            'open_datetime': datetime,\n",
    "            'close_price': close_price,\n",
    "            'close_datetime': close_datetime,\n",
    "            'profit': None,\n",
    "            'quantity': quantity,\n",
    "            'profit_as_a_percentage': None,\n",
    "            'take_profit_percentage': take_profit_percentage,\n",
    "            'stop_loss_percentage': stop_loss_percentage,\n",
    "            'take_profit_price': None,\n",
    "            'stop_loss_price': None\n",
    "        }\n",
    "\n",
    "        if take_profit_percentage is not None:\n",
    "            row['take_profit_price'] = (row['take_profit_percentage'] + 100) * price / 100\n",
    "\n",
    "        if stop_loss_percentage is not None:\n",
    "            row['stop_loss_price'] = (100 - row['stop_loss_percentage']) * price / 100\n",
    "\n",
    "        self.orders.loc[self.orders.shape[0]] = row\n",
    "\n",
    "        open_trades_count = len(self.get_open_orders())\n",
    "\n",
    "        if open_trades_count > self.max_simultaneous_open_trades_count:\n",
    "            self.max_simultaneous_open_trades_count = open_trades_count\n",
    "\n",
    "        self.balance = self.balance - quantity - quantity * self.fee / 100\n",
    "\n",
    "        return self.orders.iloc[-1].name\n",
    "\n",
    "    def is_order_closed(self, index: int):\n",
    "        if self.orders.at[index, 'close_price'] or self.orders.at[index, 'close_datetime']:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def close_order(self, index: int, price: float, datetime: str) -> bool:\n",
    "\n",
    "        index = int(index)\n",
    "\n",
    "        if self.is_order_closed(index):\n",
    "            return False\n",
    "\n",
    "        self.orders.at[index, 'close_price'] = float(price)\n",
    "        self.orders.at[index, 'close_datetime'] = str(datetime)\n",
    "\n",
    "        order = self.orders.iloc[index]\n",
    "\n",
    "        fee_for_opening_trade = order['quantity'] * self.fee / 100\n",
    "        fee_for_closing_trade = order['quantity'] * self.fee / 100\n",
    "\n",
    "        if order['type'] == 'long':\n",
    "\n",
    "            profit_as_a_percentage_without_commission = order['close_price'] * 100 / order['open_price'] - 100\n",
    "\n",
    "            amount_on_close_trade = (order['quantity'] * (100 + profit_as_a_percentage_without_commission) / 100)\n",
    "\n",
    "            self.balance += amount_on_close_trade - fee_for_closing_trade\n",
    "\n",
    "            self.orders.at[index, 'profit'] = amount_on_close_trade - order['quantity'] - fee_for_opening_trade - fee_for_closing_trade\n",
    "            self.orders.at[index, 'profit_as_a_percentage'] = profit_as_a_percentage_without_commission - self.fee * 2\n",
    "\n",
    "        elif order['type'] == 'short':\n",
    "\n",
    "            profit_as_a_percentage_without_commission = 100 - order['close_price'] * 100 / order['open_price']\n",
    "\n",
    "            amount_on_close_trade = (order['quantity'] * (100 + profit_as_a_percentage_without_commission) / 100)\n",
    "\n",
    "            self.balance += amount_on_close_trade - fee_for_closing_trade\n",
    "\n",
    "            self.orders.at[index, 'profit'] = amount_on_close_trade - order['quantity'] - fee_for_opening_trade \\\n",
    "                                              - fee_for_closing_trade\n",
    "            self.orders.at[index, 'profit_as_a_percentage'] = profit_as_a_percentage_without_commission - self.fee * 2\n",
    "\n",
    "        return True\n",
    "\n",
    "    def get_open_orders(self) -> DataFrame:\n",
    "        return self.orders[(self.orders['close_price'].isna()) & (pd.notna(self.orders['open_datetime']))]\n",
    "\n",
    "    def get_closed_orders(self) -> DataFrame:\n",
    "        return self.orders[pd.notna(self.orders['close_price'])]\n",
    "\n",
    "    def get_profit(self) -> float:\n",
    "        return self.orders['profit'].sum()\n",
    "\n",
    "    def get_profit_as_a_percentage(self) -> float:\n",
    "        return self.orders['profit_as_a_percentage'].sum()\n",
    "\n",
    "    def get_opened_orders_count(self) -> int:\n",
    "        return len(self.get_open_orders())\n",
    "\n",
    "    def get_closed_orders_count(self) -> int:\n",
    "        return len(self.get_closed_orders())\n",
    "\n",
    "    def get_win_trades(self) -> DataFrame:\n",
    "        closed = self.get_closed_orders()\n",
    "        return closed[closed['profit_as_a_percentage'] > 0]\n",
    "\n",
    "    def get_loss_trades(self) -> DataFrame:\n",
    "        closed = self.get_closed_orders()\n",
    "        return closed[closed['profit_as_a_percentage'] < 0]\n",
    "\n",
    "    def get_win_ration(self) -> float:\n",
    "        return 100 * len(self.get_win_trades()) / self.get_trades_count()\n",
    "\n",
    "    def get_trades_count(self) -> int:\n",
    "        return self.get_closed_orders_count()\n",
    "\n",
    "    def has_opened_orders(self) -> bool:\n",
    "        return len(self.get_open_orders()) > 0\n",
    "\n",
    "    def get_max_simultaneous_open_trades_count(self):\n",
    "        return self.max_simultaneous_open_trades_count\n",
    "\n",
    "    def get_pending_orders(self):\n",
    "        return self.orders[(self.orders['open_datetime'].isna()) & (pd.notna(self.orders['open_price']))]\n",
    "\n",
    "    def tick(self, candlestick):\n",
    "\n",
    "        open_trades = self.get_open_orders()\n",
    "\n",
    "        if len(open_trades) > 0:\n",
    "\n",
    "            for index, item in open_trades[candlestick['low'] < open_trades['stop_loss_price']].iterrows():\n",
    "                self.close_order(index, item['stop_loss_price'], candlestick['datetime'])\n",
    "\n",
    "            for index, item in open_trades[candlestick['high'] > open_trades['take_profit_price']].iterrows():\n",
    "                self.close_order(index, item['take_profit_price'], candlestick['datetime'])\n",
    "\n",
    "        pending_orders = self.get_pending_orders()\n",
    "\n",
    "        if len(pending_orders) > 0:\n",
    "\n",
    "            long_pending_orders = pending_orders[pending_orders['type'] == 'long']\n",
    "\n",
    "            for index, item in long_pending_orders[(candlestick['low'] < long_pending_orders['open_price']) & (\n",
    "                    candlestick['high'] > long_pending_orders['open_price'])].iterrows():\n",
    "                self.open_order(index, candlestick['datetime'])\n",
    "\n",
    "    def open_order(self, index: int, open_datetime: np.str):\n",
    "        self.orders.at[index, 'open_datetime'] = open_datetime\n",
    "\n",
    "    def backtest(self, df: DataFrame):\n",
    "        pbar = tqdm(df.iterrows(), total=len(df), colour='green')\n",
    "\n",
    "        for index, candlestick in pbar:\n",
    "            self.tick(candlestick=candlestick)\n",
    "            pbar.set_description(\n",
    "                f\"Strategy backtesting {index} Balance: {self.get_available_balance()} Open trades: {len(self.get_open_orders())} \")\n",
    "\n",
    "    def close_all_open_trades(self, candlestick):\n",
    "\n",
    "        open_trades = self.get_open_orders()\n",
    "\n",
    "        for index, item in open_trades.iterrows():\n",
    "            self.close_order(index, candlestick['close'], candlestick['datetime'])\n",
    "\n",
    "        pending_trades = self.get_pending_orders()\n",
    "\n",
    "        for index, item in pending_trades.iterrows():\n",
    "            self.cancel_order(index)\n",
    "\n",
    "    def get_available_balance(self) -> float:\n",
    "        return self.balance\n",
    "\n",
    "    def get_start_balance(self) -> float:\n",
    "        return self.start_balance\n",
    "\n",
    "    def cancel_order(self, index: int) -> bool:\n",
    "\n",
    "        index = int(index)\n",
    "\n",
    "        self.orders.drop([index], inplace=True)\n",
    "\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "WNCqm5ki9PTy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07398230582475662 0.059185844659805295\n"
     ]
    }
   ],
   "source": [
    "MAX_POSITION = dataframe_with_prediction['position'].max()\n",
    "LIMIT = 80 * MAX_POSITION / 100\n",
    "\n",
    "print(MAX_POSITION, LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "I6GR99b8miKy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LSTMStrategy(Strategy):\n",
    "    fee = 0.1\n",
    "    order_id = None\n",
    "\n",
    "    def append_indicators(self, df: DataFrame) -> DataFrame:\n",
    "        #df.ta.rsi(length=self.rsi, append=True)\n",
    "\n",
    "        df = df.fillna(0)\n",
    "\n",
    "        df = (df.replace((np.inf, -np.inf), np.nan).dropna())\n",
    "\n",
    "        return df\n",
    "\n",
    "    def tick(self, candlestick):\n",
    "        super().tick(candlestick)\n",
    "\n",
    "        if self.get_opened_orders_count() < 1:\n",
    "          if candlestick['position'] > LIMIT:\n",
    "              self.order_id = self.put_order(\n",
    "                  type='long',\n",
    "                  price=candlestick['close'],\n",
    "                  datetime=candlestick['datetime'],\n",
    "                  quantity=500,\n",
    "                  take_profit_percentage=TAKE_PROFIT_PERCENT,\n",
    "                  stop_loss_percentage=STOP_LOSS_PERCENT\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "d6gZULRCmzBB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "strategy = LSTMStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "lEvl7HYtm3Ax",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Strategy backtesting 1654700760.0 Balance: 1009.0 Open trades: 0 : 100%|\u001B[32m███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████\u001B[0m| 2000/2000 [00:06<00:00, 318.39it/s]\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "strategy.backtest(dataframe_with_prediction)\n",
    "strategy.close_all_open_trades(dataframe_with_prediction.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "DSWig8CJm4NR",
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   type  open_price       open_datetime close_price       close_datetime  \\\n0  long     30273.7 2022-06-08 04:47:00   30879.174  2022-06-08 13:49:00   \n\n  profit  quantity profit_as_a_percentage  take_profit_percentage  \\\n0    9.0     500.0                    1.8                     2.0   \n\n   stop_loss_percentage  take_profit_price  stop_loss_price  \n0                   1.0          30879.174        29970.963  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>open_price</th>\n      <th>open_datetime</th>\n      <th>close_price</th>\n      <th>close_datetime</th>\n      <th>profit</th>\n      <th>quantity</th>\n      <th>profit_as_a_percentage</th>\n      <th>take_profit_percentage</th>\n      <th>stop_loss_percentage</th>\n      <th>take_profit_price</th>\n      <th>stop_loss_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>long</td>\n      <td>30273.7</td>\n      <td>2022-06-08 04:47:00</td>\n      <td>30879.174</td>\n      <td>2022-06-08 13:49:00</td>\n      <td>9.0</td>\n      <td>500.0</td>\n      <td>1.8</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>30879.174</td>\n      <td>29970.963</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy.get_orders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M24Yz03vaU0R",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Результаты тестирования стратегии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "zphEeVNam7lR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start balance: 1000\n",
      "Available balance: 1009.0\n",
      "Profit as percentage: 1.8\n",
      "Profit: 9.0\n",
      "Win ratio: 100.0\n",
      "Max simultaneous trades count: 1\n"
     ]
    }
   ],
   "source": [
    "if len(strategy.get_orders()):\n",
    "  print(f'Start balance: {strategy.get_start_balance()}')\n",
    "  print(f'Available balance: {strategy.get_available_balance()}')\n",
    "  print(f'Profit as percentage: {strategy.get_profit_as_a_percentage()}')\n",
    "  print(f'Profit: {strategy.get_profit()}')\n",
    "  print(f'Win ratio: {strategy.get_win_ration()}')\n",
    "  print(f'Max simultaneous trades count: {strategy.get_max_simultaneous_open_trades_count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Take Profit and Stop Loss prediction training DATA LEAK",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}