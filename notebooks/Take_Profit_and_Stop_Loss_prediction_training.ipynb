{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-EViPnrPitGR",
    "outputId": "d0614f8f-5450-46d4-d00f-f2d9e2dcf1e8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/user/.local/lib/python3.10/site-packages (1.3.5)\n",
      "Requirement already satisfied: pandas-ta in /home/user/.local/lib/python3.10/site-packages (0.3.14b0)\n",
      "Requirement already satisfied: plotly in /home/user/.local/lib/python3.10/site-packages (5.8.0)\n",
      "Requirement already satisfied: ZigZag in /home/user/.local/lib/python3.10/site-packages (0.2.2)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (1.8.0)\n",
      "Requirement already satisfied: TA-Lib in /usr/local/lib/python3.10/dist-packages (0.4.24)\n",
      "Requirement already satisfied: tensorflow in /home/user/.local/lib/python3.10/site-packages (2.9.0)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/scikit-learn/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting scikit-learn\n",
      "  Using cached scikit_learn-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.4 MB)\n",
      "Requirement already satisfied: tqdm in /home/user/.local/lib/python3.10/site-packages (4.54.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/user/.local/lib/python3.10/site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/user/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/user/.local/lib/python3.10/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/user/.local/lib/python3.10/site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: packaging in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (0.25.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (3.20.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: setuptools in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (62.3.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.46.1)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/user/.local/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/user/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/user/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/user/.local/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.5.18)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/user/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.1.0 scikit-learn-1.1.1 threadpoolctl-3.1.0\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install pandas pandas-ta plotly ZigZag scipy TA-Lib tensorflow scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "h2Dm9p3kpLW0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "from sklearn.preprocessing import scale\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cj-Ayxtk9wq4"
   },
   "source": [
    "# Переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "id": "AlGqCKMLei7T"
   },
   "outputs": [],
   "source": [
    "NAME = 'Take profit and stop loss prediction'\n",
    "TIME_INTERVAL = 900\n",
    "TAKE_STEPS_TO_WATCH = 64\n",
    "INPUT_WIDTH = 512\n",
    "LSTM_INPUT_WIDTH = 512\n",
    "TAKE_PROFIT_PERCENT = 3\n",
    "STOP_LOSS_PERCENT = 1\n",
    "CURRENCY_PAIR = 'btc_usdt'\n",
    "DROPOUT = 0.01        # 0.1\n",
    "L2_REGULARIZERS = 0.002 # 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "id": "SEmF6VgY2n_G"
   },
   "outputs": [],
   "source": [
    "LOOKAHEAD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/d/Users/Neon/PycharmProjects/tradingBot/notebooks'"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-PrH0opapXA7",
    "outputId": "a96c3e43-2104-42c4-b2d1-2c2274ba7dea"
   },
   "outputs": [],
   "source": [
    "RATES_PATH = f\"{os.getcwd()}/../csv\"\n",
    "EXAMPLE_PATH = f\"{os.getcwd()}/checkpoints/\"\n",
    "\n",
    "if LOOKAHEAD:\n",
    "  dataleak = 'DATA LEAK '\n",
    "else:\n",
    "  dataleak = ''\n",
    "\n",
    "CHECKPOINT_PATH = f\"{EXAMPLE_PATH}/{dataleak}{NAME} {CURRENCY_PAIR.upper()} {TIME_INTERVAL} steps {TAKE_STEPS_TO_WATCH} iw {INPUT_WIDTH} lstm {LSTM_INPUT_WIDTH} tp {TAKE_PROFIT_PERCENT} sl {STOP_LOSS_PERCENT}/\"\n",
    "\n",
    "if not os.path.exists(EXAMPLE_PATH):\n",
    "  os.mkdir(EXAMPLE_PATH)\n",
    "\n",
    "if not os.path.exists(CHECKPOINT_PATH):\n",
    "  os.mkdir(CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SClSJNEipayw"
   },
   "source": [
    "# Функция индикаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "id": "7pFng62WhkwW"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def append_all_indicators(df):\n",
    "\n",
    "  df = append_candles_indicators(df)\n",
    "  df = append_overlap_indicators(df)\n",
    "  df = append_momentum_indicators(df)\n",
    "  df = append_statistics_indicators(df)\n",
    "  df = append_trend_indicators(df)\n",
    "  df = append_aberration_indicators(df)\n",
    "  df = append_volume_indicators(df)\n",
    "  \n",
    "  return df\n",
    "\n",
    "def append_candles_indicators(df):\n",
    "\n",
    "  names = [\n",
    "           \"2crows\",\n",
    "          \"3blackcrows\",\n",
    "          \"3inside\",\n",
    "          \"3linestrike\",\n",
    "          \"3outside\",\n",
    "          \"3starsinsouth\",\n",
    "          \"3whitesoldiers\",\n",
    "          \"abandonedbaby\",\n",
    "          \"advanceblock\",\n",
    "          \"belthold\",\n",
    "          \"breakaway\",\n",
    "          \"closingmarubozu\",\n",
    "          \"concealbabyswall\",\n",
    "          \"counterattack\",\n",
    "          \"darkcloudcover\",\n",
    "          \"doji\",\n",
    "          \"dojistar\",\n",
    "          \"dragonflydoji\",\n",
    "          \"engulfing\",\n",
    "          \"eveningdojistar\",\n",
    "          \"eveningstar\",\n",
    "          \"gapsidesidewhite\",\n",
    "          \"gravestonedoji\",\n",
    "          \"hammer\",\n",
    "          \"hangingman\",\n",
    "          \"harami\",\n",
    "          \"haramicross\",\n",
    "          \"highwave\",\n",
    "          \"hikkake\",\n",
    "          \"hikkakemod\",\n",
    "          \"homingpigeon\",\n",
    "          \"identical3crows\",\n",
    "          \"inneck\",\n",
    "          \"inside\",\n",
    "          \"invertedhammer\",\n",
    "          \"kicking\",\n",
    "          \"kickingbylength\",\n",
    "          \"ladderbottom\",\n",
    "          \"longleggeddoji\",\n",
    "          \"longline\",\n",
    "          \"marubozu\",\n",
    "          \"matchinglow\",\n",
    "          \"mathold\",\n",
    "          \"morningdojistar\",\n",
    "          \"morningstar\",\n",
    "          \"onneck\",\n",
    "          \"piercing\",\n",
    "          \"rickshawman\",\n",
    "          \"risefall3methods\",\n",
    "          \"separatinglines\",\n",
    "          \"shootingstar\",\n",
    "          \"shortline\",\n",
    "          \"spinningtop\",\n",
    "          \"stalledpattern\",\n",
    "          \"sticksandwich\",\n",
    "          \"takuri\",\n",
    "          \"tasukigap\",\n",
    "          \"thrusting\",\n",
    "          \"tristar\",\n",
    "          \"unique3river\",\n",
    "          \"upsidegap2crows\",\n",
    "          \"xsidegap3methods\"\n",
    "  ]\n",
    "\n",
    "  df.ta.cdl_pattern(name=names, append=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_momentum_indicators(df):\n",
    "\n",
    "  df.ta.apo(append=True)\n",
    "  df.ta.bias(append=True)\n",
    "  df.ta.bop(append=True)\n",
    "  df.ta.brar(append=True)\n",
    "  df.ta.cci(append=True)\n",
    "  df.ta.cfo(append=True)\n",
    "  df.ta.cg(append=True)\n",
    "  df.ta.cmo(append=True)\n",
    "  df.ta.coppock(append=True)\n",
    "  df.ta.cti(append=True)\n",
    "  df.ta.dm(append=True)\n",
    "  df.ta.er(append=True)\n",
    "  df.ta.eri(append=True)\n",
    "  df.ta.fisher(append=True)\n",
    "  df.ta.inertia(append=True)\n",
    "  df.ta.kdj(append=True)\n",
    "  df.ta.kst(append=True)\n",
    "  df.ta.macd(append=True, )\n",
    "  df.ta.mom(append=True)\n",
    "  df.ta.pgo(append=True)\n",
    "  df.ta.ppo(append=True)\n",
    "  df.ta.psl(append=True)\n",
    "  df.ta.pvo(append=True)\n",
    "  df.ta.qqe(append=True)\n",
    "  df.ta.roc(append=True)\n",
    "  df.ta.rsi(append=True)\n",
    "  df.ta.rsx(append=True)\n",
    "  df.ta.rvgi(append=True)\n",
    "  # df.ta.stc(append=True) вываливается ошибка\n",
    "  df.ta.slope(append=True)\n",
    "  df.ta.smi(append=True)\n",
    "  df.ta.squeeze(append=True) \n",
    "  df.ta.squeeze_pro(append=True) \n",
    "  df.ta.stoch(append=True)\n",
    "  df.ta.stochrsi(append=True)\n",
    "  #df.ta.td_seq(append=True)   # медленный\n",
    "  df['TD_SEQ_UP'] = 0\n",
    "  df['TD_SEQ_DN'] = 0\n",
    "  df.ta.trix(append=True)\n",
    "  df.ta.tsi(append=True)\n",
    "  df.ta.uo(append=True)\n",
    "  df.ta.willr(append=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_overlap_indicators(df):\n",
    "\n",
    "  df.ta.alma(append=True)\n",
    "  df.ta.dema(append=True)\n",
    "  df.ta.ema(append=True)\n",
    "  df.ta.fwma(append=True)\n",
    "  df.ta.hilo(append=True)\n",
    "  df.ta.hl2(append=True)\n",
    "  df.ta.hlc3(append=True)\n",
    "  df.ta.hma(append=True)\n",
    "  df.ta.hwma(append=True)\n",
    "  df.ta.ichimoku(append=True, lookahead=LOOKAHEAD) # data leak\n",
    "  #df.ta.jma(append=True)\n",
    "  df.ta.kama(append=True)\n",
    "  df.ta.linreg(append=True)\n",
    "  df.ta.mcgd(append=True)\n",
    "  df.ta.midpoint(append=True)\n",
    "  df.ta.midprice(append=True)\n",
    "  df.ta.ohlc4(append=True)\n",
    "  df.ta.pwma(append=True)\n",
    "  df.ta.rma(append=True)\n",
    "  df.ta.sinwma(append=True)\n",
    "  df.ta.sma(append=True)\n",
    "  df.ta.ssf(append=True)\n",
    "  df.ta.supertrend(append=True)\n",
    "  df.ta.swma(append=True)\n",
    "  df.ta.t3(append=True)\n",
    "  df.ta.tema(append=True)\n",
    "  df.ta.trima(append=True)\n",
    "  df.ta.vidya(append=True)\n",
    "  #df.ta.vwap(append=True) ошибка\n",
    "  df.ta.vwma(append=True)\n",
    "  df.ta.wcp(append=True) \n",
    "  df.ta.wma(append=True) \n",
    "  df.ta.zlma(append=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_statistics_indicators(df):\n",
    "  df.ta.entropy(append=True)\n",
    "  df.ta.kurtosis(append=True)\n",
    "  df.ta.mad(append=True)\n",
    "  df.ta.median(append=True)\n",
    "  df.ta.quantile(append=True)\n",
    "  df.ta.skew(append=True)\n",
    "  df.ta.stdev(append=True)\n",
    "\n",
    "  if LOOKAHEAD:\n",
    "    df.ta.tos_stdevall(append=True) #возможная утечка данных в будущее\n",
    "  else:\n",
    "    df['TOS_STDEVALL_LR'] = 0\n",
    "    df['TOS_STDEVALL_L_1'] = 0\n",
    "    df['TOS_STDEVALL_U_1'] = 0\n",
    "    df['TOS_STDEVALL_L_2'] = 0\n",
    "    df['TOS_STDEVALL_U_2'] = 0\n",
    "    df['TOS_STDEVALL_L_3'] = 0\n",
    "    df['TOS_STDEVALL_U_3'] = 0\n",
    "\n",
    "  df.ta.variance(append=True)\n",
    "  df.ta.zscore(append=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_trend_indicators(df):\n",
    "  df.ta.adx(append=True)\n",
    "  df.ta.amat(append=True)\n",
    "  df.ta.aroon(append=True)\n",
    "  df.ta.chop(append=True)\n",
    "  df.ta.cksp(append=True)\n",
    "  #df.ta.decay(append=True) ошибка\n",
    "  df.ta.decreasing(append=True)\n",
    "  df.ta.dpo(append=True, lookahead=LOOKAHEAD) # data leak\n",
    "  df.ta.increasing(append=True)\n",
    "  df.ta.long_run(append=True)\n",
    "  df.ta.psar(append=True)\n",
    "  df.ta.qstick(append=True)\n",
    "  df.ta.short_run(append=True)\n",
    "  df.ta.tsignals(append=True)\n",
    "  df.ta.ttm_trend(append=True)\n",
    "  df.ta.vhf(append=True)\n",
    "  df.ta.vortex(append=True)\n",
    "  df.ta.xsignals(append=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_utility_indicators(df):\n",
    "  # не работают\n",
    "  df.ta.above(append=True)\n",
    "  df.ta.above_value(append=True)\n",
    "  df.ta.below(append=True)\n",
    "  df.ta.below_value(append=True)\n",
    "  df.ta.cross(append=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_aberration_indicators(df):\n",
    "  df.ta.aberration(append=True)\n",
    "  df.ta.accbands(append=True)\n",
    "  df.ta.atr(append=True)\n",
    "  df.ta.bbands(append=True)\n",
    "  df.ta.donchian(append=True)\n",
    "  #df.ta.hwc(append=True) ошибка\n",
    "  df.ta.kc(append=True)\n",
    "  df.ta.massi(append=True)\n",
    "  df.ta.natr(append=True)\n",
    "  df.ta.pdist(append=True)\n",
    "  df.ta.rvi(append=True)\n",
    "  df.ta.thermo(append=True)\n",
    "  df.ta.true_range(append=True)\n",
    "  df.ta.ui(append=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_volume_indicators(df):\n",
    "  df.ta.ad(append=True)\n",
    "  df.ta.adosc(append=True)\n",
    "  df.ta.aobv(append=True)\n",
    "  df.ta.cmf(append=True)\n",
    "  df.ta.efi(append=True)\n",
    "  df.ta.eom(append=True)\n",
    "  df.ta.kvo(append=True)\n",
    "  df.ta.mfi(append=True)\n",
    "  df.ta.nvi(append=True)\n",
    "  df.ta.obv(append=True)\n",
    "  df.ta.pvi(append=True)\n",
    "  df.ta.pvol(append=True)\n",
    "  df.ta.pvr(append=True)\n",
    "  df.ta.pvt(append=True)\n",
    "  df.ta.vp(append=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def append_cycles(df):\n",
    "  #df.ta.ebsw(append=True) появляется ошибка \n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "id": "x8W2efycINfP"
   },
   "outputs": [],
   "source": [
    "def append_indicators(df):\n",
    "\n",
    "  #df.ta.macd(append=True, fast=12, slow=26, signal=9)\n",
    "  #df.ta.macd(append=True, fast=8, slow=17, signal=9)\n",
    "  #df.ta.ema(append=True, length=200)\n",
    "  #df.ta.stoch(append=True, k=14, d=3)\n",
    "  #df.ta.rsi(append=True, length=14)\n",
    "\n",
    "  df = append_all_indicators(df)\n",
    "\n",
    "  #for length in range(5, 200):\n",
    "  #  df.ta.ema(append=True, length=length)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WdDeR-VtrjOf",
    "outputId": "3036db70-6edc-4a29-e415-42d7c26884d8"
   },
   "outputs": [],
   "source": [
    "file_name = f'{CURRENCY_PAIR}_{TIME_INTERVAL}.csv.zip'\n",
    "\n",
    "file_path = f'file://{RATES_PATH}/{file_name}'\n",
    "\n",
    "df = pd.read_csv(file_path, decimal='.', keep_default_na=False, encoding = \"UTF-8\", compression='zip')\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "df = (df.replace((np.inf, -np.inf), np.nan)\n",
    "                     .dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-12 08:30:00</td>\n",
       "      <td>5077.574899</td>\n",
       "      <td>5077.574899</td>\n",
       "      <td>5077.574899</td>\n",
       "      <td>5077.574899</td>\n",
       "      <td>0.001190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-12 08:45:00</td>\n",
       "      <td>5070.978000</td>\n",
       "      <td>5070.978000</td>\n",
       "      <td>5070.978000</td>\n",
       "      <td>5070.978000</td>\n",
       "      <td>0.001190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-12 09:00:00</td>\n",
       "      <td>5070.978000</td>\n",
       "      <td>5070.978000</td>\n",
       "      <td>5070.978000</td>\n",
       "      <td>5070.978000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-12 09:15:00</td>\n",
       "      <td>5070.978000</td>\n",
       "      <td>5070.978000</td>\n",
       "      <td>5070.978000</td>\n",
       "      <td>5070.978000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-12 09:30:00</td>\n",
       "      <td>5070.978000</td>\n",
       "      <td>5070.978000</td>\n",
       "      <td>5070.978000</td>\n",
       "      <td>5070.978000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161696</th>\n",
       "      <td>2022-05-23 16:30:00</td>\n",
       "      <td>30422.930000</td>\n",
       "      <td>30402.170000</td>\n",
       "      <td>30350.010000</td>\n",
       "      <td>30454.550000</td>\n",
       "      <td>26.364489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161697</th>\n",
       "      <td>2022-05-23 16:45:00</td>\n",
       "      <td>30408.180000</td>\n",
       "      <td>30264.590000</td>\n",
       "      <td>30162.090000</td>\n",
       "      <td>30408.180000</td>\n",
       "      <td>30.137711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161698</th>\n",
       "      <td>2022-05-23 17:00:00</td>\n",
       "      <td>30264.590000</td>\n",
       "      <td>30146.210000</td>\n",
       "      <td>30043.810000</td>\n",
       "      <td>30265.400000</td>\n",
       "      <td>31.911468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161699</th>\n",
       "      <td>2022-05-23 17:15:00</td>\n",
       "      <td>30135.980000</td>\n",
       "      <td>30095.590000</td>\n",
       "      <td>30093.630000</td>\n",
       "      <td>30136.470000</td>\n",
       "      <td>0.314766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161700</th>\n",
       "      <td>2022-05-23 17:30:00</td>\n",
       "      <td>30118.760000</td>\n",
       "      <td>30138.950000</td>\n",
       "      <td>30074.470000</td>\n",
       "      <td>30193.190000</td>\n",
       "      <td>1.775732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161701 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime          open         close           low  \\\n",
       "0       2017-10-12 08:30:00   5077.574899   5077.574899   5077.574899   \n",
       "1       2017-10-12 08:45:00   5070.978000   5070.978000   5070.978000   \n",
       "2       2017-10-12 09:00:00   5070.978000   5070.978000   5070.978000   \n",
       "3       2017-10-12 09:15:00   5070.978000   5070.978000   5070.978000   \n",
       "4       2017-10-12 09:30:00   5070.978000   5070.978000   5070.978000   \n",
       "...                     ...           ...           ...           ...   \n",
       "161696  2022-05-23 16:30:00  30422.930000  30402.170000  30350.010000   \n",
       "161697  2022-05-23 16:45:00  30408.180000  30264.590000  30162.090000   \n",
       "161698  2022-05-23 17:00:00  30264.590000  30146.210000  30043.810000   \n",
       "161699  2022-05-23 17:15:00  30135.980000  30095.590000  30093.630000   \n",
       "161700  2022-05-23 17:30:00  30118.760000  30138.950000  30074.470000   \n",
       "\n",
       "                high     volume  \n",
       "0        5077.574899   0.001190  \n",
       "1        5070.978000   0.001190  \n",
       "2        5070.978000   0.000000  \n",
       "3        5070.978000   0.000000  \n",
       "4        5070.978000   0.000000  \n",
       "...              ...        ...  \n",
       "161696  30454.550000  26.364489  \n",
       "161697  30408.180000  30.137711  \n",
       "161698  30265.400000  31.911468  \n",
       "161699  30136.470000   0.314766  \n",
       "161700  30193.190000   1.775732  \n",
       "\n",
       "[161701 rows x 6 columns]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "id": "QHqsoesS3rgP"
   },
   "outputs": [],
   "source": [
    "def processing(df, row, take_steps_to_watch):\n",
    "\n",
    "  index = row.name\n",
    "\n",
    "  loc = df.index.get_loc(index) + 1\n",
    "\n",
    "  sample = df.iloc[loc:loc + take_steps_to_watch]\n",
    "\n",
    "  position = 0\n",
    "\n",
    "  for index, sample_row in sample.iterrows():\n",
    "    if sample_row['high'] >= row['long_take_profit_price']:\n",
    "      return 1\n",
    "    if sample_row['low'] <= row['long_stop_loss_price']:\n",
    "      return 0\n",
    "      \n",
    "  return position\n",
    "\n",
    "def append_position(original_df):\n",
    "\n",
    "  df = original_df.copy()\n",
    "\n",
    "  df['long_take_profit_price'] = (100 + TAKE_PROFIT_PERCENT) * df['close'] / 100\n",
    "  df['long_stop_loss_price'] = (100 - STOP_LOSS_PERCENT) * df['close'] / 100\n",
    "\n",
    "  for index, row in df.iterrows():\n",
    "    df.at[index, 'position'] = processing(df, row, TAKE_STEPS_TO_WATCH)\n",
    "\n",
    "  original_df['position'] = df['position']\n",
    "\n",
    "  return original_df\n",
    "\n",
    "df = append_position(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "id": "S5QWK_fG0RG-"
   },
   "outputs": [],
   "source": [
    "def append_position(original_df):\n",
    "\n",
    "  df = original_df.copy()\n",
    "\n",
    "  df[f'future_high_{TAKE_STEPS_TO_WATCH}'] = df['high'].rolling(TAKE_STEPS_TO_WATCH).max().shift(-TAKE_STEPS_TO_WATCH)\n",
    "  df[f'future_low_{TAKE_STEPS_TO_WATCH}'] = df['low'].rolling(TAKE_STEPS_TO_WATCH).min().shift(-TAKE_STEPS_TO_WATCH)\n",
    "\n",
    "  df[f'future_high_{TAKE_STEPS_TO_WATCH}_percentage'] = (df[f'future_high_{TAKE_STEPS_TO_WATCH}'] * 100 / df['close']) - 100\n",
    "  df[f'future_low_{TAKE_STEPS_TO_WATCH}_percentage'] = 100 - (df[f'future_low_{TAKE_STEPS_TO_WATCH}'] * 100 / df['close'])\n",
    "\n",
    "  df['long_position'] = 0\n",
    "\n",
    "  df.loc[(df[f'future_high_{TAKE_STEPS_TO_WATCH}_percentage'] > TAKE_PROFIT_PERCENT) & (df[f'future_low_{TAKE_STEPS_TO_WATCH}_percentage'] < STOP_LOSS_PERCENT), 'long_position'] = 1\n",
    "\n",
    "  df['short_position'] = 0\n",
    "\n",
    "  df.loc[(df[f'future_high_{TAKE_STEPS_TO_WATCH}_percentage'] < STOP_LOSS_PERCENT) & (df[f'future_low_{TAKE_STEPS_TO_WATCH}_percentage'] > TAKE_PROFIT_PERCENT), 'short_position'] = 1\n",
    "\n",
    "  df['position'] = 0\n",
    "\n",
    "  df.loc[df['long_position'] > 0, 'position'] = 1\n",
    "  df.loc[df['short_position'] > 0, 'position'] = -1\n",
    "\n",
    "  original_df['position'] = df['position']\n",
    "\n",
    "  return original_df\n",
    "\n",
    "#df = append_position(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdoSQg9EIT85",
    "outputId": "041f5261-0d47-4a68-e736-2ba7888c17a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long trend count: 26959\n",
      "Neutral trend count: 134742\n",
      "Short trend count: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Long trend count:\", len(df[df['position'] > 0]))\n",
    "print(\"Neutral trend count:\", len(df[df['position'] == 0]))\n",
    "print(\"Short trend count:\", len(df[df['position'] < 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "id": "6QrAbL2Whs7G"
   },
   "outputs": [],
   "source": [
    "df = append_indicators(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XizdWj5Ccp-o",
    "outputId": "d8e1fff6-7cbc-44ed-ae97-d52fbb1cfcf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['datetime', 'CDL_2CROWS', 'CDL_3BLACKCROWS', 'CDL_3INSIDE',\n",
       "       'CDL_3LINESTRIKE', 'CDL_3OUTSIDE', 'CDL_3STARSINSOUTH',\n",
       "       'CDL_3WHITESOLDIERS', 'CDL_ABANDONEDBABY', 'CDL_ADVANCEBLOCK',\n",
       "       'CDL_BELTHOLD', 'CDL_BREAKAWAY', 'CDL_CLOSINGMARUBOZU',\n",
       "       'CDL_CONCEALBABYSWALL', 'CDL_COUNTERATTACK', 'CDL_DARKCLOUDCOVER',\n",
       "       'CDL_DOJI_10_0.1', 'CDL_DOJISTAR', 'CDL_DRAGONFLYDOJI',\n",
       "       'CDL_ENGULFING', 'CDL_EVENINGDOJISTAR', 'CDL_EVENINGSTAR',\n",
       "       'CDL_GAPSIDESIDEWHITE', 'CDL_GRAVESTONEDOJI', 'CDL_HAMMER',\n",
       "       'CDL_HANGINGMAN', 'CDL_HARAMI', 'CDL_HARAMICROSS', 'CDL_HIGHWAVE',\n",
       "       'CDL_HIKKAKE', 'CDL_HIKKAKEMOD', 'CDL_HOMINGPIGEON',\n",
       "       'CDL_IDENTICAL3CROWS', 'CDL_INNECK', 'CDL_INSIDE',\n",
       "       'CDL_INVERTEDHAMMER', 'CDL_KICKING', 'CDL_KICKINGBYLENGTH',\n",
       "       'CDL_LADDERBOTTOM', 'CDL_LONGLEGGEDDOJI', 'CDL_LONGLINE',\n",
       "       'CDL_MARUBOZU', 'CDL_MATCHINGLOW', 'CDL_MATHOLD',\n",
       "       'CDL_MORNINGDOJISTAR', 'CDL_MORNINGSTAR', 'CDL_ONNECK',\n",
       "       'CDL_PIERCING', 'CDL_RICKSHAWMAN', 'CDL_RISEFALL3METHODS',\n",
       "       'CDL_SEPARATINGLINES', 'CDL_SHOOTINGSTAR', 'CDL_SHORTLINE',\n",
       "       'CDL_SPINNINGTOP', 'CDL_STALLEDPATTERN', 'CDL_STICKSANDWICH',\n",
       "       'CDL_TAKURI', 'CDL_TASUKIGAP', 'CDL_THRUSTING', 'CDL_TRISTAR',\n",
       "       'CDL_UNIQUE3RIVER', 'CDL_UPSIDEGAP2CROWS', 'CDL_XSIDEGAP3METHODS',\n",
       "       'ALMA_10_6.0_0.85', 'DEMA_10', 'EMA_10', 'FWMA_10', 'HILO_13_21',\n",
       "       'HILOl_13_21', 'HILOs_13_21', 'HL2', 'HLC3', 'HMA_10',\n",
       "       'HWMA_0.2_0.1_0.1', 'ISA_9', 'ISB_26', 'ITS_9', 'IKS_26',\n",
       "       'KAMA_10_2_30', 'LR_14', 'MCGD_10', 'MIDPOINT_2', 'MIDPRICE_2',\n",
       "       'OHLC4', 'PWMA_10', 'RMA_10', 'SINWMA_14', 'SMA_10', 'SSF_10_2',\n",
       "       'SUPERT_7_3.0', 'SUPERTd_7_3.0', 'SUPERTl_7_3.0', 'SUPERTs_7_3.0',\n",
       "       'SWMA_10', 'T3_10_0.7', 'TEMA_10', 'TRIMA_10', 'VIDYA_14',\n",
       "       'VWMA_10', 'WCP', 'WMA_10', 'ZL_EMA_10', 'APO_12_26',\n",
       "       'BIAS_SMA_26', 'BOP', 'AR_26', 'BR_26', 'CCI_14_0.015', 'CFO_9',\n",
       "       'CG_10', 'CMO_14', 'COPC_11_14_10', 'CTI_12', 'DMP_14', 'DMN_14',\n",
       "       'ER_10', 'BULLP_13', 'BEARP_13', 'FISHERT_9_1', 'FISHERTs_9_1',\n",
       "       'INERTIA_20_14', 'K_9_3', 'D_9_3', 'J_9_3',\n",
       "       'KST_10_15_20_30_10_10_10_15', 'KSTs_9', 'MACD_12_26_9',\n",
       "       'MACDh_12_26_9', 'MACDs_12_26_9', 'MOM_10', 'PGO_14',\n",
       "       'PPO_12_26_9', 'PPOh_12_26_9', 'PPOs_12_26_9', 'PSL_12',\n",
       "       'PVO_12_26_9', 'PVOh_12_26_9', 'PVOs_12_26_9', 'QQE_14_5_4.236',\n",
       "       'QQE_14_5_4.236_RSIMA', 'QQEl_14_5_4.236', 'QQEs_14_5_4.236',\n",
       "       'ROC_10', 'RSI_14', 'RSX_14', 'RVGI_14_4', 'RVGIs_14_4', 'SLOPE_1',\n",
       "       'SMI_5_20_5', 'SMIs_5_20_5', 'SMIo_5_20_5', 'SQZ_20_2.0_20_1.5',\n",
       "       'SQZ_ON', 'SQZ_OFF', 'SQZ_NO', 'SQZPRO_20_2.0_20_2_1.5_1',\n",
       "       'SQZPRO_ON_WIDE', 'SQZPRO_ON_NORMAL', 'SQZPRO_ON_NARROW',\n",
       "       'SQZPRO_OFF', 'SQZPRO_NO', 'STOCHk_14_3_3', 'STOCHd_14_3_3',\n",
       "       'STOCHRSIk_14_14_3_3', 'STOCHRSId_14_14_3_3', 'TD_SEQ_UP',\n",
       "       'TD_SEQ_DN', 'TRIX_30_9', 'TRIXs_30_9', 'TSI_13_25_13',\n",
       "       'TSIs_13_25_13', 'UO_7_14_28', 'WILLR_14', 'ENTP_10', 'KURT_30',\n",
       "       'MAD_30', 'MEDIAN_30', 'QTL_30_0.5', 'SKEW_30', 'STDEV_30',\n",
       "       'TOS_STDEVALL_LR', 'TOS_STDEVALL_L_1', 'TOS_STDEVALL_U_1',\n",
       "       'TOS_STDEVALL_L_2', 'TOS_STDEVALL_U_2', 'TOS_STDEVALL_L_3',\n",
       "       'TOS_STDEVALL_U_3', 'VAR_30', 'ZS_30', 'ADX_14', 'AMATe_LR_8_21_2',\n",
       "       'AMATe_SR_8_21_2', 'AROOND_14', 'AROONU_14', 'AROONOSC_14',\n",
       "       'CHOP_14_1_100', 'CKSPl_10_3_20', 'CKSPs_10_3_20', 'DEC_1',\n",
       "       'DPO_20', 'INC_1', 'PSARl_0.02_0.2', 'PSARs_0.02_0.2',\n",
       "       'PSARaf_0.02_0.2', 'PSARr_0.02_0.2', 'QS_10', 'TTM_TRND_6',\n",
       "       'VHF_28', 'VTXP_14', 'VTXM_14', 'ABER_ZG_5_15', 'ABER_SG_5_15',\n",
       "       'ABER_XG_5_15', 'ABER_ATR_5_15', 'ACCBL_20', 'ACCBM_20',\n",
       "       'ACCBU_20', 'ATRr_14', 'BBL_5_2.0', 'BBM_5_2.0', 'BBU_5_2.0',\n",
       "       'BBB_5_2.0', 'BBP_5_2.0', 'DCL_20_20', 'DCM_20_20', 'DCU_20_20',\n",
       "       'KCLe_20_2', 'KCBe_20_2', 'KCUe_20_2', 'MASSI_9_25', 'NATR_14',\n",
       "       'PDIST', 'RVI_14', 'THERMO_20_2_0.5', 'THERMOma_20_2_0.5',\n",
       "       'THERMOl_20_2_0.5', 'THERMOs_20_2_0.5', 'TRUERANGE_1', 'UI_14',\n",
       "       'AD', 'ADOSC_3_10', 'OBV', 'OBV_min_2', 'OBV_max_2', 'OBVe_4',\n",
       "       'OBVe_12', 'AOBV_LR_2', 'AOBV_SR_2', 'CMF_20', 'EFI_13',\n",
       "       'EOM_14_100000000', 'KVO_34_55_13', 'KVOs_34_55_13', 'MFI_14',\n",
       "       'NVI_1', 'PVI_1', 'PVOL', 'PVR', 'PVT', 'low_close', 'mean_close',\n",
       "       'high_close', 'pos_volume', 'neg_volume', 'total_volume'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = df.columns\n",
    "\n",
    "features_names_with_position = index.delete([\n",
    "                                             index.get_loc('volume'), \n",
    "                                             index.get_loc('close'),\n",
    "                                             index.get_loc('open'), \n",
    "                                             index.get_loc('high'), \n",
    "                                             index.get_loc('low'),\n",
    "                                             ])\n",
    "\n",
    "FEATURES_NAMES = features_names_with_position.delete([features_names_with_position.get_loc('position')]).values\n",
    "\n",
    "FEATURES_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "id": "Sno5eQ3QgcKd"
   },
   "outputs": [],
   "source": [
    "data = df.loc[:,features_names_with_position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data)\n",
    "max_val_df_length = 10000\n",
    "max_eval_df_length = 10000\n",
    "val_length = int(n*0.9) - int(n*0.8)\n",
    "eval_length = int(n*1) - int(n*0.9)\n",
    "\n",
    "if val_length > max_val_df_length:\n",
    "    val_length = max_val_df_length\n",
    "    \n",
    "if eval_length > max_eval_df_length:\n",
    "    eval_length = max_eval_df_length\n",
    "\n",
    "val_start_index = n - eval_length - val_length\n",
    "test_start_index = n - eval_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161701 141701 151701\n"
     ]
    }
   ],
   "source": [
    "print(n, val_start_index, test_start_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SNcqnMrogkv7",
    "outputId": "a7ed430c-7d35-4d2c-ca49-47026dcace3f"
   },
   "outputs": [],
   "source": [
    "train_df = data[0:val_start_index]\n",
    "val_df = data[val_start_index:test_start_index]\n",
    "test_df = data[test_start_index:]\n",
    "\n",
    "test_full_df = df[test_start_index:]\n",
    "\n",
    "num_features = data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161701 141701 10000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(data), len(train_df), len(val_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "id": "Oiad03Ja3LPH"
   },
   "outputs": [],
   "source": [
    "def normalization(dataframe, train_mean, train_std):\n",
    "  position = dataframe.pop('position')\n",
    "  dataframe = (dataframe - train_mean) / train_std\n",
    "  dataframe['position'] = position\n",
    "  return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzjrB6DCgtsK",
    "outputId": "2aecd1ee-f74d-404f-a7b4-35832f8af872"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16806/3095889046.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  train_mean = train_df.mean()\n",
      "/tmp/ipykernel_16806/3095889046.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  train_std = train_df.std()\n"
     ]
    }
   ],
   "source": [
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_df = normalization(train_df, train_mean, train_std)\n",
    "val_df = normalization(val_df, train_mean, train_std)\n",
    "test_df = normalization(test_df, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7801Z5WwgwDi",
    "outputId": "2c6ebe1d-bde6-401c-ed06-d3cb4d4ab527"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position                0.169392\n",
      "CDL_2CROWS             -0.032463\n",
      "CDL_3BLACKCROWS        -0.037403\n",
      "CDL_3INSIDE             0.109385\n",
      "CDL_3LINESTRIKE         0.019054\n",
      "                       ...      \n",
      "mean_close          19756.277849\n",
      "high_close          29247.932000\n",
      "pos_volume         139063.407772\n",
      "neg_volume         140297.129487\n",
      "total_volume       279360.537259\n",
      "Length: 265, dtype: float64 position                0.375099\n",
      "CDL_2CROWS              1.801455\n",
      "CDL_3BLACKCROWS         1.933623\n",
      "CDL_3INSIDE            11.115708\n",
      "CDL_3LINESTRIKE         4.803807\n",
      "                       ...      \n",
      "mean_close          17903.194580\n",
      "high_close          24071.801013\n",
      "pos_volume          74785.481637\n",
      "neg_volume          74934.125837\n",
      "total_volume       149602.986716\n",
      "Length: 265, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u492P34ygy-S",
    "outputId": "86be81f3-9340-465a-d879-6eacb9285357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141701 10000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df), len(val_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "vB4ypH2Hjbht",
    "outputId": "a0522a28-aa8f-48f1-a0f2-b32dd7b9f7e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABER_ATR_5_15</th>\n",
       "      <th>ABER_SG_5_15</th>\n",
       "      <th>ABER_XG_5_15</th>\n",
       "      <th>ABER_ZG_5_15</th>\n",
       "      <th>ACCBL_20</th>\n",
       "      <th>ACCBM_20</th>\n",
       "      <th>ACCBU_20</th>\n",
       "      <th>AD</th>\n",
       "      <th>ADOSC_3_10</th>\n",
       "      <th>ADX_14</th>\n",
       "      <th>...</th>\n",
       "      <th>ZL_EMA_10</th>\n",
       "      <th>ZS_30</th>\n",
       "      <th>datetime</th>\n",
       "      <th>high_close</th>\n",
       "      <th>low_close</th>\n",
       "      <th>mean_close</th>\n",
       "      <th>neg_volume</th>\n",
       "      <th>pos_volume</th>\n",
       "      <th>position</th>\n",
       "      <th>total_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ABER_ATR_5_15, ABER_SG_5_15, ABER_XG_5_15, ABER_ZG_5_15, ACCBL_20, ACCBM_20, ACCBU_20, AD, ADOSC_3_10, ADX_14, ALMA_10_6.0_0.85, AMATe_LR_8_21_2, AMATe_SR_8_21_2, AOBV_LR_2, AOBV_SR_2, APO_12_26, AROOND_14, AROONOSC_14, AROONU_14, AR_26, ATRr_14, BBB_5_2.0, BBL_5_2.0, BBM_5_2.0, BBP_5_2.0, BBU_5_2.0, BEARP_13, BIAS_SMA_26, BOP, BR_26, BULLP_13, CCI_14_0.015, CDL_2CROWS, CDL_3BLACKCROWS, CDL_3INSIDE, CDL_3LINESTRIKE, CDL_3OUTSIDE, CDL_3STARSINSOUTH, CDL_3WHITESOLDIERS, CDL_ABANDONEDBABY, CDL_ADVANCEBLOCK, CDL_BELTHOLD, CDL_BREAKAWAY, CDL_CLOSINGMARUBOZU, CDL_CONCEALBABYSWALL, CDL_COUNTERATTACK, CDL_DARKCLOUDCOVER, CDL_DOJISTAR, CDL_DOJI_10_0.1, CDL_DRAGONFLYDOJI, CDL_ENGULFING, CDL_EVENINGDOJISTAR, CDL_EVENINGSTAR, CDL_GAPSIDESIDEWHITE, CDL_GRAVESTONEDOJI, CDL_HAMMER, CDL_HANGINGMAN, CDL_HARAMI, CDL_HARAMICROSS, CDL_HIGHWAVE, CDL_HIKKAKE, CDL_HIKKAKEMOD, CDL_HOMINGPIGEON, CDL_IDENTICAL3CROWS, CDL_INNECK, CDL_INSIDE, CDL_INVERTEDHAMMER, CDL_KICKING, CDL_KICKINGBYLENGTH, CDL_LADDERBOTTOM, CDL_LONGLEGGEDDOJI, CDL_LONGLINE, CDL_MARUBOZU, CDL_MATCHINGLOW, CDL_MATHOLD, CDL_MORNINGDOJISTAR, CDL_MORNINGSTAR, CDL_ONNECK, CDL_PIERCING, CDL_RICKSHAWMAN, CDL_RISEFALL3METHODS, CDL_SEPARATINGLINES, CDL_SHOOTINGSTAR, CDL_SHORTLINE, CDL_SPINNINGTOP, CDL_STALLEDPATTERN, CDL_STICKSANDWICH, CDL_TAKURI, CDL_TASUKIGAP, CDL_THRUSTING, CDL_TRISTAR, CDL_UNIQUE3RIVER, CDL_UPSIDEGAP2CROWS, CDL_XSIDEGAP3METHODS, CFO_9, CG_10, CHOP_14_1_100, CKSPl_10_3_20, CKSPs_10_3_20, CMF_20, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 266 columns]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.fillna(0)\n",
    "val_df = val_df.fillna(0)\n",
    "test_df = test_df.fillna(0)\n",
    "\n",
    "train_df[train_df.isnull().any(axis=1)]\n",
    "train_df[train_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "id": "f9ARLeUAg2ua"
   },
   "outputs": [],
   "source": [
    "assert train_df.isnull().values.any() == False, 'Тренировочный датафрейм не должен содержать nan значений'\n",
    "assert val_df.isnull().values.any() == False, 'Датафрейм валидации не должен содержать nan значений'\n",
    "assert test_df.isnull().values.any() == False, 'Тестовый датафрейм не должен содержать nan значений'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "id": "IDwhAGpWceQJ"
   },
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,\n",
    "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "               label_columns=None, input_columns=None):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    # Work out the label column indices.\n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "\n",
    "    self.input_columns = input_columns\n",
    "\n",
    "    self.input_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(input_columns)}   \n",
    "\n",
    "    self.label_columns = label_columns\n",
    "\n",
    "    self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}                       \n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "  def __repr__(self):\n",
    "    return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Column indices: {self.column_indices}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}',\n",
    "        f'Label start: {self.label_start}',\n",
    "        f'Input width: {self.input_width}',\n",
    "        f'Label width: {self.label_width}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "id": "JaaeyIqnciCo"
   },
   "outputs": [],
   "source": [
    "def make_dataset(self, data, shuffle=True, batch_size=32,):\n",
    "  data = np.array(data, dtype=np.float32)\n",
    "\n",
    "  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size)\n",
    "\n",
    "  ds = ds.map(self.split_window)\n",
    "\n",
    "  return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "id": "38kyb3tPckMp"
   },
   "outputs": [],
   "source": [
    "@property\n",
    "def train(self):\n",
    "  return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "  return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "  return self.make_dataset(self.test_df)\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "  result = getattr(self, '_example', None)\n",
    "  if result is None:\n",
    "    # No example batch was found, so get one from the `.train` dataset\n",
    "    result = next(iter(self.train))\n",
    "    # And cache it for next time\n",
    "    self._example = result\n",
    "  return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "id": "la6ecAfPcgq4"
   },
   "outputs": [],
   "source": [
    "def split_window(self, features):\n",
    "  inputs = features[:, self.input_slice, :]\n",
    "  labels = features[:, self.labels_slice, :]\n",
    "\n",
    "  inputs = tf.stack(\n",
    "        [inputs[:, :, self.column_indices[name]] for name in self.input_columns],\n",
    "        axis=-1)\n",
    "  \n",
    "  labels = tf.stack(\n",
    "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "        axis=-1)\n",
    "\n",
    "  # Slicing doesn't preserve static shape information, so set the shapes\n",
    "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "  inputs.set_shape([None, self.input_width, None])\n",
    "  labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "  return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "id": "iUY869JCcgw3"
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "  def __init__(self, model, path, max_epochs=30, patience=3):\n",
    "    self.model = model\n",
    "    self.path = path\n",
    "    self.max_epochs = max_epochs\n",
    "    self.patience = patience\n",
    "\n",
    "  def compile(self):\n",
    "    self.model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                  optimizer=tf.optimizers.Adam(learning_rate=0.0005),\n",
    "                  metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "  def load_weights(self):\n",
    "    self.model.load_weights(self.path)\n",
    "\n",
    "  def fit(self, window):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                      patience=self.patience,\n",
    "                                                      mode='min')\n",
    "\n",
    "    # Create a callback that saves the model's weights\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=self.path,\n",
    "                                                    save_weights_only=True,\n",
    "                                                    verbose=1)\n",
    "\n",
    "    history = self.model.fit(window.train, epochs=self.max_epochs,\n",
    "                        validation_data=window.val,\n",
    "                        callbacks=[early_stopping, cp_callback])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "id": "FV4lB3DXcifH"
   },
   "outputs": [],
   "source": [
    "wide_window = WindowGenerator(\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    input_width=INPUT_WIDTH, label_width=1, shift=1,\n",
    "    label_columns=['position'], input_columns=FEATURES_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "id": "zj4BOQBYhRXI"
   },
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(LSTM_INPUT_WIDTH, activation='tanh', return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(L2_REGULARIZERS)),\n",
    "    tf.keras.layers.Dropout(DROPOUT),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQIR9s1MpgMp"
   },
   "source": [
    "# Тренировка нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "id": "_tI8qaAXmGcS"
   },
   "outputs": [],
   "source": [
    "model = Model(lstm_model, CHECKPOINT_PATH, max_epochs=20, patience=3)\n",
    "model.compile()\n",
    "\n",
    "if os.path.exists(f'{CHECKPOINT_PATH}/checkpoint'):\n",
    "  model.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SOYH_oU4AUnr",
    "outputId": "10203c13-92e6-4956-8154-ca12fbeb8d82",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4413/4413 [==============================] - ETA: 0s - loss: 0.2022 - mean_absolute_error: 0.2769\n",
      "Epoch 1: saving model to /mnt/d/Users/Neon/PycharmProjects/tradingBot/notebooks/checkpoints//Take profit and stop loss prediction BTC_USDT 900 steps 64 iw 512 lstm 512 tp 3 sl 1/\n",
      "4413/4413 [==============================] - 10020s 2s/step - loss: 0.2022 - mean_absolute_error: 0.2769 - val_loss: 0.1319 - val_mean_absolute_error: 0.2895\n",
      "Epoch 2/20\n",
      "4413/4413 [==============================] - ETA: 0s - loss: 0.1373 - mean_absolute_error: 0.2689\n",
      "Epoch 2: saving model to /mnt/d/Users/Neon/PycharmProjects/tradingBot/notebooks/checkpoints//Take profit and stop loss prediction BTC_USDT 900 steps 64 iw 512 lstm 512 tp 3 sl 1/\n",
      "4413/4413 [==============================] - 10026s 2s/step - loss: 0.1373 - mean_absolute_error: 0.2689 - val_loss: 0.1322 - val_mean_absolute_error: 0.2933\n",
      "Epoch 3/20\n",
      "4413/4413 [==============================] - ETA: 0s - loss: 0.1357 - mean_absolute_error: 0.2641\n",
      "Epoch 3: saving model to /mnt/d/Users/Neon/PycharmProjects/tradingBot/notebooks/checkpoints//Take profit and stop loss prediction BTC_USDT 900 steps 64 iw 512 lstm 512 tp 3 sl 1/\n",
      "4413/4413 [==============================] - 10035s 2s/step - loss: 0.1357 - mean_absolute_error: 0.2641 - val_loss: 0.1313 - val_mean_absolute_error: 0.2805\n",
      "Epoch 4/20\n",
      "4413/4413 [==============================] - ETA: 0s - loss: 0.1333 - mean_absolute_error: 0.2595\n",
      "Epoch 4: saving model to /mnt/d/Users/Neon/PycharmProjects/tradingBot/notebooks/checkpoints//Take profit and stop loss prediction BTC_USDT 900 steps 64 iw 512 lstm 512 tp 3 sl 1/\n",
      "4413/4413 [==============================] - 10451s 2s/step - loss: 0.1333 - mean_absolute_error: 0.2595 - val_loss: 0.1325 - val_mean_absolute_error: 0.2818\n",
      "Epoch 5/20\n",
      "4413/4413 [==============================] - ETA: 0s - loss: 0.1322 - mean_absolute_error: 0.2560\n",
      "Epoch 5: saving model to /mnt/d/Users/Neon/PycharmProjects/tradingBot/notebooks/checkpoints//Take profit and stop loss prediction BTC_USDT 900 steps 64 iw 512 lstm 512 tp 3 sl 1/\n",
      "4413/4413 [==============================] - 10763s 2s/step - loss: 0.1322 - mean_absolute_error: 0.2560 - val_loss: 0.1369 - val_mean_absolute_error: 0.3091\n",
      "Epoch 6/20\n",
      "4413/4413 [==============================] - ETA: 0s - loss: 0.1378 - mean_absolute_error: 0.2614\n",
      "Epoch 6: saving model to /mnt/d/Users/Neon/PycharmProjects/tradingBot/notebooks/checkpoints//Take profit and stop loss prediction BTC_USDT 900 steps 64 iw 512 lstm 512 tp 3 sl 1/\n",
      "4413/4413 [==============================] - 10566s 2s/step - loss: 0.1378 - mean_absolute_error: 0.2614 - val_loss: 0.1353 - val_mean_absolute_error: 0.2966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faf5b868700>"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(wide_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "id": "29HDmO6QH7SH"
   },
   "outputs": [],
   "source": [
    "@property\n",
    "def test_without_shuffle(self):\n",
    "\n",
    "  return self.make_dataset(self.test_df, shuffle=False)\n",
    "\n",
    "WindowGenerator.test_without_shuffle = test_without_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "id": "ZthrB3EB0td6"
   },
   "outputs": [],
   "source": [
    "model = lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "id": "iXwTd2Gshwta"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 251s 842ms/step - loss: 0.1307 - mean_absolute_error: 0.2768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1306837648153305, 0.27681708335876465]"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(wide_window.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "id": "AvkBGld3INOX"
   },
   "outputs": [],
   "source": [
    "dataset = wide_window.test_without_shuffle.map(lambda x, y: model(x)).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "id": "QNejnl8OvbA_"
   },
   "outputs": [],
   "source": [
    "index = test_full_df.iloc[0].name\n",
    "\n",
    "before = np.full(INPUT_WIDTH, 0.0)\n",
    "after = np.fromiter(dataset.as_numpy_iterator(), np.float32)\n",
    "\n",
    "position_prediction_df = pd.DataFrame(data=np.concatenate((before, after), axis=0), columns=['position'], index=test_full_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "id": "oyl4hhCnvl8d"
   },
   "outputs": [],
   "source": [
    "dataframe_with_prediction = pd.concat([position_prediction_df, test_full_df.drop(columns=['position'])], axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "id": "PYGucvT_mS66",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16806/4095104747.py:179: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def open_order(self, index: int, open_datetime: np.str):\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "from pandas import DataFrame\n",
    "class Strategy:\n",
    "    fee = 0.2\n",
    "    # ограничение на максимальное количество открытых сделок\n",
    "    max_simultaneous_open_trades_limit = 1\n",
    "    # максимальное количество сделок которое было открыто одновременно\n",
    "    max_simultaneous_open_trades_count = 0\n",
    "\n",
    "    def __init__(self, max_simultaneous_open_trades_limit=1, start_balance=1000):\n",
    "        self.orders = pd.DataFrame(None,\n",
    "                                   columns=['type', 'open_price', 'open_datetime', 'close_price', 'close_datetime',\n",
    "                                            'profit', 'quantity', 'profit_as_a_percentage', 'take_profit_percentage',\n",
    "                                            'stop_loss_percentage', 'take_profit_price', 'stop_loss_price'],\n",
    "                                   ).astype({\n",
    "            'type': str, 'open_price': np.float32, 'open_datetime': str, 'close_price': np.float32,\n",
    "            'close_datetime': str,\n",
    "            'profit': np.float32, 'quantity': np.float32,\n",
    "            'profit_as_a_percentage': np.float32, 'take_profit_percentage': np.float32,\n",
    "            'stop_loss_percentage': np.float32, 'take_profit_price': np.float32, 'stop_loss_price': np.float32\n",
    "        })\n",
    "\n",
    "        self.max_simultaneous_open_trades_limit = max_simultaneous_open_trades_limit\n",
    "        self.start_balance = start_balance\n",
    "        self.balance = start_balance\n",
    "\n",
    "    def append_indicators(self, df: DataFrame) -> DataFrame:\n",
    "        return df\n",
    "\n",
    "    def get_orders(self):\n",
    "        return self.orders\n",
    "\n",
    "    def put_order(self, type: str, price: float, quantity: float, datetime: str = None,\n",
    "                  close_price: float = None, close_datetime: str = None,\n",
    "                  take_profit_percentage: float = None,\n",
    "                  stop_loss_percentage: float = None) -> int:\n",
    "\n",
    "        row = {\n",
    "            'type': type,\n",
    "            'open_price': price,\n",
    "            'open_datetime': datetime,\n",
    "            'close_price': close_price,\n",
    "            'close_datetime': close_datetime,\n",
    "            'profit': None,\n",
    "            'quantity': quantity,\n",
    "            'profit_as_a_percentage': None,\n",
    "            'take_profit_percentage': take_profit_percentage,\n",
    "            'stop_loss_percentage': stop_loss_percentage,\n",
    "            'take_profit_price': None,\n",
    "            'stop_loss_price': None\n",
    "        }\n",
    "\n",
    "        if take_profit_percentage is not None:\n",
    "            row['take_profit_price'] = (row['take_profit_percentage'] + 100) * price / 100\n",
    "\n",
    "        if stop_loss_percentage is not None:\n",
    "            row['stop_loss_price'] = (100 - row['stop_loss_percentage']) * price / 100\n",
    "\n",
    "        self.orders.loc[self.orders.shape[0]] = row\n",
    "\n",
    "        open_trades_count = len(self.get_open_orders())\n",
    "\n",
    "        if open_trades_count > self.max_simultaneous_open_trades_count:\n",
    "            self.max_simultaneous_open_trades_count = open_trades_count\n",
    "\n",
    "        self.balance = self.balance - quantity - quantity * self.fee / 100\n",
    "\n",
    "        return self.orders.iloc[-1].name\n",
    "\n",
    "    def is_order_closed(self, index: int):\n",
    "        if self.orders.at[index, 'close_price'] or self.orders.at[index, 'close_datetime']:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def close_order(self, index: int, price: float, datetime: str) -> bool:\n",
    "\n",
    "        index = int(index)\n",
    "\n",
    "        if self.is_order_closed(index):\n",
    "            return False\n",
    "\n",
    "        self.orders.at[index, 'close_price'] = float(price)\n",
    "        self.orders.at[index, 'close_datetime'] = str(datetime)\n",
    "\n",
    "        order = self.orders.iloc[index]\n",
    "\n",
    "        fee_for_opening_trade = order['quantity'] * self.fee / 100\n",
    "        fee_for_closing_trade = order['quantity'] * self.fee / 100\n",
    "\n",
    "        if order['type'] == 'long':\n",
    "\n",
    "            profit_as_a_percentage_without_commission = order['close_price'] * 100 / order['open_price'] - 100\n",
    "\n",
    "            amount_on_close_trade = (order['quantity'] * (100 + profit_as_a_percentage_without_commission) / 100)\n",
    "\n",
    "            self.balance += amount_on_close_trade - fee_for_closing_trade\n",
    "\n",
    "            self.orders.at[index, 'profit'] = amount_on_close_trade - order['quantity'] - fee_for_opening_trade - fee_for_closing_trade\n",
    "            self.orders.at[index, 'profit_as_a_percentage'] = profit_as_a_percentage_without_commission - self.fee * 2\n",
    "\n",
    "        elif order['type'] == 'short':\n",
    "\n",
    "            profit_as_a_percentage_without_commission = 100 - order['close_price'] * 100 / order['open_price']\n",
    "\n",
    "            amount_on_close_trade = (order['quantity'] * (100 + profit_as_a_percentage_without_commission) / 100)\n",
    "\n",
    "            self.balance += amount_on_close_trade - fee_for_closing_trade\n",
    "\n",
    "            self.orders.at[index, 'profit'] = amount_on_close_trade - order['quantity'] - fee_for_opening_trade \\\n",
    "                                              - fee_for_closing_trade\n",
    "            self.orders.at[index, 'profit_as_a_percentage'] = profit_as_a_percentage_without_commission - self.fee * 2\n",
    "\n",
    "        return True\n",
    "\n",
    "    def get_open_orders(self) -> DataFrame:\n",
    "        return self.orders[(self.orders['close_price'].isna()) & (pd.notna(self.orders['open_datetime']))]\n",
    "\n",
    "    def get_closed_orders(self) -> DataFrame:\n",
    "        return self.orders[pd.notna(self.orders['close_price'])]\n",
    "\n",
    "    def get_profit(self) -> float:\n",
    "        return self.orders['profit'].sum()\n",
    "\n",
    "    def get_profit_as_a_percentage(self) -> float:\n",
    "        return self.orders['profit_as_a_percentage'].sum()\n",
    "\n",
    "    def get_opened_orders_count(self) -> int:\n",
    "        return len(self.get_open_orders())\n",
    "\n",
    "    def get_closed_orders_count(self) -> int:\n",
    "        return len(self.get_closed_orders())\n",
    "\n",
    "    def get_win_trades(self) -> DataFrame:\n",
    "        closed = self.get_closed_orders()\n",
    "        return closed[closed['profit_as_a_percentage'] > 0]\n",
    "\n",
    "    def get_loss_trades(self) -> DataFrame:\n",
    "        closed = self.get_closed_orders()\n",
    "        return closed[closed['profit_as_a_percentage'] < 0]\n",
    "\n",
    "    def get_win_ration(self) -> float:\n",
    "        return 100 * len(self.get_win_trades()) / self.get_trades_count()\n",
    "\n",
    "    def get_trades_count(self) -> int:\n",
    "        return self.get_closed_orders_count()\n",
    "\n",
    "    def has_opened_orders(self) -> bool:\n",
    "        return len(self.get_open_orders()) > 0\n",
    "\n",
    "    def get_max_simultaneous_open_trades_count(self):\n",
    "        return self.max_simultaneous_open_trades_count\n",
    "\n",
    "    def get_pending_orders(self):\n",
    "        return self.orders[(self.orders['open_datetime'].isna()) & (pd.notna(self.orders['open_price']))]\n",
    "\n",
    "    def tick(self, candlestick):\n",
    "\n",
    "        open_trades = self.get_open_orders()\n",
    "\n",
    "        if len(open_trades) > 0:\n",
    "\n",
    "            for index, item in open_trades[candlestick['low'] < open_trades['stop_loss_price']].iterrows():\n",
    "                self.close_order(index, item['stop_loss_price'], candlestick['datetime'])\n",
    "\n",
    "            for index, item in open_trades[candlestick['high'] > open_trades['take_profit_price']].iterrows():\n",
    "                self.close_order(index, item['take_profit_price'], candlestick['datetime'])\n",
    "\n",
    "        pending_orders = self.get_pending_orders()\n",
    "\n",
    "        if len(pending_orders) > 0:\n",
    "\n",
    "            long_pending_orders = pending_orders[pending_orders['type'] == 'long']\n",
    "\n",
    "            for index, item in long_pending_orders[(candlestick['low'] < long_pending_orders['open_price']) & (\n",
    "                    candlestick['high'] > long_pending_orders['open_price'])].iterrows():\n",
    "                self.open_order(index, candlestick['datetime'])\n",
    "\n",
    "    def open_order(self, index: int, open_datetime: np.str):\n",
    "        self.orders.at[index, 'open_datetime'] = open_datetime\n",
    "\n",
    "    def backtest(self, df: DataFrame):\n",
    "        pbar = tqdm(df.iterrows(), total=len(df), colour='green')\n",
    "\n",
    "        for index, candlestick in pbar:\n",
    "            self.tick(candlestick=candlestick)\n",
    "            pbar.set_description(\n",
    "                f\"Strategy backtesting {index} Balance: {self.get_available_balance()} Open trades: {len(self.get_open_orders())} \")\n",
    "\n",
    "    def close_all_open_trades(self, candlestick):\n",
    "\n",
    "        open_trades = self.get_open_orders()\n",
    "\n",
    "        for index, item in open_trades.iterrows():\n",
    "            self.close_order(index, candlestick['close'], candlestick['datetime'])\n",
    "\n",
    "        pending_trades = self.get_pending_orders()\n",
    "\n",
    "        for index, item in pending_trades.iterrows():\n",
    "            self.cancel_order(index)\n",
    "\n",
    "    def get_available_balance(self) -> float:\n",
    "        return self.balance\n",
    "\n",
    "    def get_start_balance(self) -> float:\n",
    "        return self.start_balance\n",
    "\n",
    "    def cancel_order(self, index: int) -> bool:\n",
    "\n",
    "        index = int(index)\n",
    "\n",
    "        self.orders.drop([index], inplace=True)\n",
    "\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "id": "WNCqm5ki9PTy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4342438876628876 0.34739511013031005\n"
     ]
    }
   ],
   "source": [
    "MAX_POSITION = dataframe_with_prediction['position'].max()\n",
    "LIMIT = 80 * MAX_POSITION / 100\n",
    "\n",
    "print(MAX_POSITION, LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "id": "I6GR99b8miKy"
   },
   "outputs": [],
   "source": [
    "class LSTMStrategy(Strategy):\n",
    "    fee = 0.1\n",
    "    order_id = None\n",
    "\n",
    "    def append_indicators(self, df: DataFrame) -> DataFrame:\n",
    "        #df.ta.rsi(length=self.rsi, append=True)\n",
    "\n",
    "        df = df.fillna(0)\n",
    "\n",
    "        df = (df.replace((np.inf, -np.inf), np.nan).dropna())\n",
    "\n",
    "        return df\n",
    "\n",
    "    def tick(self, candlestick):\n",
    "        super().tick(candlestick)\n",
    "\n",
    "        if self.get_opened_orders_count() < 1:\n",
    "          if candlestick['position'] > LIMIT:\n",
    "              self.order_id = self.put_order(\n",
    "                  type='long',\n",
    "                  price=candlestick['close'],\n",
    "                  datetime=candlestick['datetime'],\n",
    "                  quantity=500,\n",
    "                  take_profit_percentage=TAKE_PROFIT_PERCENT,\n",
    "                  stop_loss_percentage=STOP_LOSS_PERCENT\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "id": "d6gZULRCmzBB"
   },
   "outputs": [],
   "source": [
    "strategy = LSTMStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "id": "lEvl7HYtm3Ax"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Strategy backtesting 161700 Balance: 988.0 Open trades: 0 : 100%|\u001b[32m████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 10000/10000 [00:34<00:00, 290.99it/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "strategy.backtest(dataframe_with_prediction)\n",
    "strategy.close_all_open_trades(dataframe_with_prediction.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "id": "DSWig8CJm4NR",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>open_price</th>\n",
       "      <th>open_datetime</th>\n",
       "      <th>close_price</th>\n",
       "      <th>close_datetime</th>\n",
       "      <th>profit</th>\n",
       "      <th>quantity</th>\n",
       "      <th>profit_as_a_percentage</th>\n",
       "      <th>take_profit_percentage</th>\n",
       "      <th>stop_loss_percentage</th>\n",
       "      <th>take_profit_price</th>\n",
       "      <th>stop_loss_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>long</td>\n",
       "      <td>44152.01</td>\n",
       "      <td>2022-03-01 22:30:00</td>\n",
       "      <td>43710.4899</td>\n",
       "      <td>2022-03-02 07:15:00</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45476.5703</td>\n",
       "      <td>43710.4899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>long</td>\n",
       "      <td>38461.65</td>\n",
       "      <td>2022-03-08 15:30:00</td>\n",
       "      <td>39615.4995</td>\n",
       "      <td>2022-03-09 03:15:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39615.4995</td>\n",
       "      <td>38077.0335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>long</td>\n",
       "      <td>41986.00</td>\n",
       "      <td>2022-03-19 00:30:00</td>\n",
       "      <td>41566.14</td>\n",
       "      <td>2022-03-19 03:45:00</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43245.5800</td>\n",
       "      <td>41566.1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>long</td>\n",
       "      <td>44240.98</td>\n",
       "      <td>2022-03-25 17:30:00</td>\n",
       "      <td>45568.2094</td>\n",
       "      <td>2022-03-27 20:30:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45568.2094</td>\n",
       "      <td>43798.5702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>long</td>\n",
       "      <td>38523.61</td>\n",
       "      <td>2022-05-02 02:30:00</td>\n",
       "      <td>38138.3739</td>\n",
       "      <td>2022-05-02 18:00:00</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39679.3183</td>\n",
       "      <td>38138.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>long</td>\n",
       "      <td>28361.64</td>\n",
       "      <td>2022-05-12 18:45:00</td>\n",
       "      <td>28078.0236</td>\n",
       "      <td>2022-05-12 21:30:00</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29212.4892</td>\n",
       "      <td>28078.0236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>long</td>\n",
       "      <td>28436.57</td>\n",
       "      <td>2022-05-12 21:30:00</td>\n",
       "      <td>29289.6671</td>\n",
       "      <td>2022-05-13 00:30:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29289.6671</td>\n",
       "      <td>28152.2043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>long</td>\n",
       "      <td>30384.06</td>\n",
       "      <td>2022-05-13 06:45:00</td>\n",
       "      <td>30080.2194</td>\n",
       "      <td>2022-05-13 16:30:00</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31295.5818</td>\n",
       "      <td>30080.2194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>long</td>\n",
       "      <td>29905.59</td>\n",
       "      <td>2022-05-13 16:30:00</td>\n",
       "      <td>29606.5341</td>\n",
       "      <td>2022-05-13 17:45:00</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30802.7577</td>\n",
       "      <td>29606.5341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>long</td>\n",
       "      <td>29600.00</td>\n",
       "      <td>2022-05-13 17:45:00</td>\n",
       "      <td>29304.0</td>\n",
       "      <td>2022-05-13 23:30:00</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30488.0000</td>\n",
       "      <td>29304.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>long</td>\n",
       "      <td>29240.87</td>\n",
       "      <td>2022-05-13 23:30:00</td>\n",
       "      <td>28948.4613</td>\n",
       "      <td>2022-05-14 11:15:00</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30118.0961</td>\n",
       "      <td>28948.4613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>long</td>\n",
       "      <td>30032.16</td>\n",
       "      <td>2022-05-17 00:15:00</td>\n",
       "      <td>29731.8384</td>\n",
       "      <td>2022-05-17 18:15:00</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30933.1248</td>\n",
       "      <td>29731.8384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type  open_price        open_datetime close_price       close_datetime  \\\n",
       "0   long    44152.01  2022-03-01 22:30:00  43710.4899  2022-03-02 07:15:00   \n",
       "1   long    38461.65  2022-03-08 15:30:00  39615.4995  2022-03-09 03:15:00   \n",
       "2   long    41986.00  2022-03-19 00:30:00    41566.14  2022-03-19 03:45:00   \n",
       "3   long    44240.98  2022-03-25 17:30:00  45568.2094  2022-03-27 20:30:00   \n",
       "4   long    38523.61  2022-05-02 02:30:00  38138.3739  2022-05-02 18:00:00   \n",
       "5   long    28361.64  2022-05-12 18:45:00  28078.0236  2022-05-12 21:30:00   \n",
       "6   long    28436.57  2022-05-12 21:30:00  29289.6671  2022-05-13 00:30:00   \n",
       "7   long    30384.06  2022-05-13 06:45:00  30080.2194  2022-05-13 16:30:00   \n",
       "8   long    29905.59  2022-05-13 16:30:00  29606.5341  2022-05-13 17:45:00   \n",
       "9   long    29600.00  2022-05-13 17:45:00     29304.0  2022-05-13 23:30:00   \n",
       "10  long    29240.87  2022-05-13 23:30:00  28948.4613  2022-05-14 11:15:00   \n",
       "11  long    30032.16  2022-05-17 00:15:00  29731.8384  2022-05-17 18:15:00   \n",
       "\n",
       "   profit  quantity profit_as_a_percentage  take_profit_percentage  \\\n",
       "0    -6.0     500.0                   -1.2                     3.0   \n",
       "1    14.0     500.0                    2.8                     3.0   \n",
       "2    -6.0     500.0                   -1.2                     3.0   \n",
       "3    14.0     500.0                    2.8                     3.0   \n",
       "4    -6.0     500.0                   -1.2                     3.0   \n",
       "5    -6.0     500.0                   -1.2                     3.0   \n",
       "6    14.0     500.0                    2.8                     3.0   \n",
       "7    -6.0     500.0                   -1.2                     3.0   \n",
       "8    -6.0     500.0                   -1.2                     3.0   \n",
       "9    -6.0     500.0                   -1.2                     3.0   \n",
       "10   -6.0     500.0                   -1.2                     3.0   \n",
       "11   -6.0     500.0                   -1.2                     3.0   \n",
       "\n",
       "    stop_loss_percentage  take_profit_price  stop_loss_price  \n",
       "0                    1.0         45476.5703       43710.4899  \n",
       "1                    1.0         39615.4995       38077.0335  \n",
       "2                    1.0         43245.5800       41566.1400  \n",
       "3                    1.0         45568.2094       43798.5702  \n",
       "4                    1.0         39679.3183       38138.3739  \n",
       "5                    1.0         29212.4892       28078.0236  \n",
       "6                    1.0         29289.6671       28152.2043  \n",
       "7                    1.0         31295.5818       30080.2194  \n",
       "8                    1.0         30802.7577       29606.5341  \n",
       "9                    1.0         30488.0000       29304.0000  \n",
       "10                   1.0         30118.0961       28948.4613  \n",
       "11                   1.0         30933.1248       29731.8384  "
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy.get_orders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M24Yz03vaU0R"
   },
   "source": [
    "# Результаты тестирования стратегии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "id": "zphEeVNam7lR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start balance: 1000\n",
      "Available balance: 988.0\n",
      "Profit as percentage: -2.4000000000000004\n",
      "Profit: -11.999999999999943\n",
      "Win ratio: 25.0\n",
      "Max simultaneous trades count: 1\n"
     ]
    }
   ],
   "source": [
    "if len(strategy.get_orders()):\n",
    "  print(f'Start balance: {strategy.get_start_balance()}')\n",
    "  print(f'Available balance: {strategy.get_available_balance()}')\n",
    "  print(f'Profit as percentage: {strategy.get_profit_as_a_percentage()}')\n",
    "  print(f'Profit: {strategy.get_profit()}')\n",
    "  print(f'Win ratio: {strategy.get_win_ration()}')\n",
    "  print(f'Max simultaneous trades count: {strategy.get_max_simultaneous_open_trades_count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Take Profit and Stop Loss prediction training DATA LEAK",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
